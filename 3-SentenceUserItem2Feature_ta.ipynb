{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 81,
            "source": [
                "!which python"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/u/pw7nc/anaconda3/bin/python\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "source": [
                "import re\n",
                "import json\n",
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
                "\n",
                "import spacy\n",
                "import nltk\n",
                "from nltk.tokenize import sent_tokenize, word_tokenize\n",
                "from spacy.lang.en import English\n",
                "nlp = English()\n",
                "# Create a Tokenizer with the default settings for English\n",
                "# including punctuation rules and exceptions\n",
                "tokenizer = nlp.tokenizer\n",
                "import string\n",
                "punct = string.punctuation\n",
                "from sklearn.feature_extraction import _stop_words"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "source": [
                "dataset_name = \"tripadvisor\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "source": [
                "punct"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 84
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Read Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "source": [
                "dir_path = '../Dataset/{}'.format(dataset_name)\n",
                "# Load train dataset\n",
                "train_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'train_review_filtered.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        train_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 50000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading train dataset, totally {} lines.'.format(len(train_review)))\n",
                "# Load test dataset\n",
                "test_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'test_review_filtered_clean.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        test_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 10000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading test dataset, totally {} lines.'.format(len(test_review)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/tripadvisor/train_review_filtered.json\n",
                        "50000 lines loaded.\n",
                        "100000 lines loaded.\n",
                        "150000 lines loaded.\n",
                        "200000 lines loaded.\n",
                        "Finish loading train dataset, totally 205595 lines.\n",
                        "Load file: ../Dataset/tripadvisor/test_review_filtered_clean.json\n",
                        "10000 lines loaded.\n",
                        "Finish loading test dataset, totally 19444 lines.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Convert List Data to Pandas Dataframe"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "source": [
                "df_train_data = pd.DataFrame(train_review, columns=['item', 'user', 'rating', 'review'])\n",
                "df_test_data = pd.DataFrame(test_review, columns=['item', 'user', 'rating', 'review'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "source": [
                "df_train_data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "        item user  rating                                             review\n",
                            "0          0    0       5  this is our second stay at this hotel ; we sta...\n",
                            "1          1    0       3  small , cramped rooms , moldy grout in shower ...\n",
                            "2         10    0       3  the room doors would slam when guests leave , ...\n",
                            "3        100    0       2  first , the old style tv was on top of the clo...\n",
                            "4       1000    0       5  the food was exceptional - we really enjoyed t...\n",
                            "...      ...  ...     ...                                                ...\n",
                            "205590   752  999       5  the rooms are spacious , quiet , and clean . m...\n",
                            "205591   819  999       5  room was very nice . bed was comfortable , had...\n",
                            "205592   827  999       3  not really the best stay i ever had . room was...\n",
                            "205593   852  999       3  our room was not as nice as i had hoped . the ...\n",
                            "205594   898  999       5  villas are very confortable , spacy and clean ...\n",
                            "\n",
                            "[205595 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>this is our second stay at this hotel ; we sta...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>small , cramped rooms , moldy grout in shower ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the room doors would slam when guests leave , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>100</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>first , the old style tv was on top of the clo...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the food was exceptional - we really enjoyed t...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205590</th>\n",
                            "      <td>752</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the rooms are spacious , quiet , and clean . m...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205591</th>\n",
                            "      <td>819</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>room was very nice . bed was comfortable , had...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205592</th>\n",
                            "      <td>827</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>not really the best stay i ever had . room was...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205593</th>\n",
                            "      <td>852</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>our room was not as nice as i had hoped . the ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205594</th>\n",
                            "      <td>898</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>villas are very confortable , spacy and clean ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>205595 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 87
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "source": [
                "print(\"Number of users on train: {}\\tNumber of items on train: {}\".format(\n",
                "    len(df_train_data['user'].unique()), len(df_train_data['item'].unique())\n",
                "))\n",
                "print(\"Number of users on test: {}\\tNumber of items on test: {}\".format(\n",
                "    len(df_test_data['user'].unique()), len(df_test_data['item'].unique())\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of users on train: 4950\tNumber of items on train: 4493\n",
                        "Number of users on test: 4936\tNumber of items on test: 4121\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Compute Sentence Tf-idf"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "def catDoc(textlist):\n",
                "    res = []\n",
                "    for tlist in textlist:\n",
                "        res.extend(tlist)\n",
                "    return res"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "def get_tfidf_embedding(text, feature_word_list):\n",
                "    \"\"\"\n",
                "    :param: text: list, sent_number * word\n",
                "    :return: \n",
                "        vectorizer: \n",
                "            vocabulary_: word2id\n",
                "            get_feature_names(): id2word\n",
                "        tfidf: array [sent_number, max_word_number]\n",
                "    \"\"\"\n",
                "    vectorizer = CountVectorizer(lowercase=True, vocabulary=feature_word_list)\n",
                "    word_count = vectorizer.fit_transform(text)\n",
                "    tfidf_transformer = TfidfTransformer()\n",
                "    tfidf = tfidf_transformer.fit_transform(word_count)\n",
                "    tfidf_weight = tfidf.toarray()\n",
                "    return vectorizer, tfidf_weight"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "def get_tf_score(text, feature_word_list):\n",
                "    vectorizer = CountVectorizer(lowercase=True, vocabulary=feature_word_list)\n",
                "    word_count = vectorizer.fit_transform(text)\n",
                "    return word_count.toarray()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "def get_df_score(text, feature_word_list):\n",
                "    vectorizer = CountVectorizer(lowercase=True, vocabulary=feature_word_list)\n",
                "    word_count = vectorizer.fit_transform(text)\n",
                "    # from word count (i.e. tf) get document frequency (i.e. df)\n",
                "    df_count = np.sum(word_count.toarray()>0, axis=0)\n",
                "    return df_count"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "def compress_array(a, id2word, vocab):\n",
                "    \"\"\"\n",
                "    :param a: matrix, [N, M], N is document number, M is word number\n",
                "    :param id2word: word id to word\n",
                "    :return: \n",
                "    \"\"\"\n",
                "    d = {}\n",
                "    # Loop over documents\n",
                "    for i in range(len(a)):\n",
                "        d[i] = {}\n",
                "        # Loop over words\n",
                "        for j in range(len(a[i])):\n",
                "            if a[i][j] != 0:\n",
                "                wid_voc = vocab[id2word[j]]\n",
                "                d[i][wid_voc] = a[i][j]\n",
                "    return d"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load Feature Words"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "source": [
                "feature_2_id_file = '../Dataset/{}/train/feature/feature2id.json'.format(dataset_name)\n",
                "with open(feature_2_id_file, 'r') as f:\n",
                "    print(\"Load file: {}\".format(feature_2_id_file))\n",
                "    feature_vocab = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/tripadvisor/train/feature/feature2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "source": [
                "len(feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "503"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 90
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "source": [
                "feature_vocab['wifi']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'110'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 91
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "source": [
                "feature_word_list = list(feature_vocab.keys())\n",
                "print('Number of feature words: {}'.format(len(feature_word_list)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of feature words: 503\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "source": [
                "id2feature_dict = dict()\n",
                "for key,value in feature_vocab.items():\n",
                "    id2feature_dict[value] = key"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "source": [
                "id_2_feature_file = '../Dataset/{}/train/feature/id2feature.json'.format(dataset_name)\n",
                "with open(id_2_feature_file, 'w') as f:\n",
                "    print(\"Write file: {}\".format(id_2_feature_file))\n",
                "    json.dump(id2feature_dict, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/feature/id2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Check Whether there are reviews with no sentences"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "source": [
                "invalid_data = 0\n",
                "for idx, row in df_train_data.iterrows():\n",
                "    review_text = row['review']\n",
                "    review_sents = sent_tokenize(review_text)\n",
                "    if len(review_sents) == 0:\n",
                "        print(row)\n",
                "        invalid_data += 1\n",
                "print(\"Invalid reviews: {}\".format(invalid_data))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Invalid reviews: 0\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construct Sentence Vocab"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "source": [
                "# sentence vocab\n",
                "sentence_count = dict()\n",
                "sentence_with_no_feature = 0\n",
                "# Loop for each review\n",
                "for idx, row in df_train_data.iterrows():\n",
                "    review_text = row['review']\n",
                "    review_sents = sent_tokenize(review_text)\n",
                "    tf_score = get_tf_score(review_sents, feature_word_list)\n",
                "    # _, tf_score = get_tfidf_embedding(review_sents, feature_word_list)\n",
                "    # Sum up the tf-value for each sentence so that if this sum is 0, this sentence should be removed\n",
                "    tfidf_sum_sents = np.sum(tf_score, axis=1)\n",
                "    for i in range(len(review_sents)):\n",
                "        if tfidf_sum_sents[i] != 0.0:\n",
                "            cur_sent = review_sents[i]\n",
                "            # check whether this sentence has more than 3 tokens\n",
                "            tokens = word_tokenize(cur_sent)\n",
                "            cnt_tokens = 0\n",
                "            for token in tokens:\n",
                "                if token.isdigit() or (token in punct):\n",
                "                    pass\n",
                "                else:\n",
                "                    cnt_tokens += 1\n",
                "            # only sentence with more than (or equal to) 2 effective tokens \n",
                "            # can be added into the sentence vocab\n",
                "            if cnt_tokens < 2:\n",
                "                pass\n",
                "            else:\n",
                "                sentence_count[cur_sent] = 1 + sentence_count.get(cur_sent, 0)\n",
                "        else:\n",
                "            sentence_with_no_feature += 1\n",
                "    if (idx+1) % 10000 == 0:\n",
                "        print(\"Processed {} lines\".format(idx+1))\n",
                "print('Finish. Totally {} lines'.format(idx+1))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Processed 10000 lines\n",
                        "Processed 20000 lines\n",
                        "Processed 30000 lines\n",
                        "Processed 40000 lines\n",
                        "Processed 50000 lines\n",
                        "Processed 60000 lines\n",
                        "Processed 70000 lines\n",
                        "Processed 80000 lines\n",
                        "Processed 90000 lines\n",
                        "Processed 100000 lines\n",
                        "Processed 110000 lines\n",
                        "Processed 120000 lines\n",
                        "Processed 130000 lines\n",
                        "Processed 140000 lines\n",
                        "Processed 150000 lines\n",
                        "Processed 160000 lines\n",
                        "Processed 170000 lines\n",
                        "Processed 180000 lines\n",
                        "Processed 190000 lines\n",
                        "Processed 200000 lines\n",
                        "Finish. Totally 205595 lines\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "source": [
                "print(\"Number of sentences with feature word(s): {0}\\nNumber of sentences w/o feature word: {1}\".format(\n",
                "    len(sentence_count), sentence_with_no_feature\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of sentences with feature word(s): 740398\n",
                        "Number of sentences w/o feature word: 11436\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "source": [
                "# sort sentence based on counts (the majority should be 1)\n",
                "sorted_sent_counts = sorted(sentence_count.items(), key = lambda x: -x[1])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "source": [
                "# sentence_vocab_list = list(sentence_count.keys())\n",
                "# Building mappings from sentences to ids and ids to sentences\n",
                "sent_to_id = {entry[0]: str(id) for (id, entry) in enumerate(sorted_sent_counts)}\n",
                "# Since we loaded all the tokenized sentences, we don't need to add the special UNK token\n",
                "id_to_sent = {str(id): sent for (sent, id) in sent_to_id.items()}"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "source": [
                "assert len(sent_to_id) == len(id_to_sent)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "source": [
                "id_to_sent['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'great location .'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 101
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "source": [
                "id2sentence_filepath = '../Dataset/{}/train/sentence/id2sentence.json'.format(dataset_name)\n",
                "with open(id2sentence_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(id2sentence_filepath))\n",
                "    json.dump(id_to_sent, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/sentence/id2sentence.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "source": [
                "sentence2id_filepath = '../Dataset/{}/train/sentence/sentence2id.json'.format(dataset_name)\n",
                "with open(sentence2id_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(sentence2id_filepath))\n",
                "    json.dump(sent_to_id, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/sentence/sentence2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "source": [
                "# Load id2sentence and sentence2id, check whether they are the same as the newly processed mappings\n",
                "id2sentence_filepath = '../Dataset/{}/train/sentence/id2sentence.json'.format(dataset_name)\n",
                "with open(id2sentence_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(id2sentence_filepath))\n",
                "    trainset_id2sent = json.load(f)\n",
                "sentence2id_filepath = '../Dataset/{}/train/sentence/sentence2id.json'.format(dataset_name)\n",
                "with open(sentence2id_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(sentence2id_filepath))\n",
                "    trainset_sent2id = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/tripadvisor/train/sentence/id2sentence.json\n",
                        "Load file: ../Dataset/tripadvisor/train/sentence/sentence2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "source": [
                "assert trainset_id2sent == id_to_sent\n",
                "assert trainset_sent2id == sent_to_id"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Get Sentence Feature"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "source": [
                "df_train_data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "        item user  rating                                             review\n",
                            "0          0    0       5  this is our second stay at this hotel ; we sta...\n",
                            "1          1    0       3  small , cramped rooms , moldy grout in shower ...\n",
                            "2         10    0       3  the room doors would slam when guests leave , ...\n",
                            "3        100    0       2  first , the old style tv was on top of the clo...\n",
                            "4       1000    0       5  the food was exceptional - we really enjoyed t...\n",
                            "...      ...  ...     ...                                                ...\n",
                            "205590   752  999       5  the rooms are spacious , quiet , and clean . m...\n",
                            "205591   819  999       5  room was very nice . bed was comfortable , had...\n",
                            "205592   827  999       3  not really the best stay i ever had . room was...\n",
                            "205593   852  999       3  our room was not as nice as i had hoped . the ...\n",
                            "205594   898  999       5  villas are very confortable , spacy and clean ...\n",
                            "\n",
                            "[205595 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>this is our second stay at this hotel ; we sta...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>small , cramped rooms , moldy grout in shower ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the room doors would slam when guests leave , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>100</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>first , the old style tv was on top of the clo...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the food was exceptional - we really enjoyed t...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205590</th>\n",
                            "      <td>752</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the rooms are spacious , quiet , and clean . m...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205591</th>\n",
                            "      <td>819</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>room was very nice . bed was comfortable , had...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205592</th>\n",
                            "      <td>827</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>not really the best stay i ever had . room was...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205593</th>\n",
                            "      <td>852</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>our room was not as nice as i had hoped . the ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205594</th>\n",
                            "      <td>898</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>villas are very confortable , spacy and clean ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>205595 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 106
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "source": [
                "def check_vocab_is_same(sklearn_vocab, feature_vocab):\n",
                "    if len(sklearn_vocab) == len(feature_vocab):\n",
                "        for key, value in sklearn_vocab.items():\n",
                "            sklearn_vocab_id = value\n",
                "            feature_vocab_id = feature_vocab[key]\n",
                "            if int(feature_vocab_id) == sklearn_vocab_id:\n",
                "                continue\n",
                "            else:\n",
                "                return False\n",
                "    else:\n",
                "        return False\n",
                "    return True"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "source": [
                "sentence_text_list = list(sent_to_id.keys())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "source": [
                "len(sentence_text_list)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "740398"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 109
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "source": [
                "sentence_text_list[:10]"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "['great location .',\n",
                            " 'i would stay here again .',\n",
                            " 'i would definitely stay here again .',\n",
                            " 'the staff was very friendly and helpful .',\n",
                            " 'friendly staff .',\n",
                            " 'the staff was friendly and helpful .',\n",
                            " 'would definitely stay here again .',\n",
                            " 'very comfortable .',\n",
                            " 'would stay here again .',\n",
                            " 'very clean .']"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 110
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "source": [
                "cntvector, tfidf_weight = get_tfidf_embedding(sentence_text_list, feature_word_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "source": [
                "df_count = get_df_score(sentence_text_list, feature_word_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "source": [
                "df_count.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(503,)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 113
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "source": [
                "trainset_feature_df = dict()\n",
                "trainset_feature_df_norm = dict()\n",
                "for i in range(len(feature_word_list)):\n",
                "    trainset_feature_df[feature_word_list[i]] = df_count[i]\n",
                "    trainset_feature_df_norm[feature_word_list[i]] = df_count[i]/len(sentence_text_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "source": [
                "type(trainset_feature_df['wifi'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "numpy.int64"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 115
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 116,
            "source": [
                "for key, value in trainset_feature_df.items():\n",
                "    if isinstance(value, np.int64):\n",
                "        trainset_feature_df[key] = int(value)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 117,
            "source": [
                "type(trainset_feature_df['wifi'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "int"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 117
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "source": [
                "trainset_feat_df_file = '../Dataset/{}/train/feature/feature2df.json'.format(dataset_name)\n",
                "\n",
                "with open(trainset_feat_df_file, 'w') as f:\n",
                "    print(\"Write file: {}\".format(trainset_feat_df_file))\n",
                "    json.dump(trainset_feature_df, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/feature/feature2df.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 119,
            "source": [
                "trainset_feature_df_sort = dict(sorted(trainset_feature_df.items(), key = lambda x: -x[1]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 120,
            "source": [
                "trainset_feature_df_sort_list = list(trainset_feature_df_sort.keys())\n",
                "trainset_feature_df_sort_rank = dict()\n",
                "for i in range(len(trainset_feature_df_sort_list)):\n",
                "    trainset_feature_df_sort_rank[trainset_feature_df_sort_list[i]] = i+1"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 121,
            "source": [
                "this_word = 'wifi'\n",
                "print(\"df value: {}\".format(trainset_feature_df[this_word]))\n",
                "print(\"rank of the feature: {}\".format(trainset_feature_df_sort_rank[this_word]))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "df value: 3422\n",
                        "rank of the feature: 111\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 122,
            "source": [
                "tfidf_weight.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(740398, 503)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 122
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "source": [
                "check_vocab_is_same(cntvector.vocabulary_, feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 123
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "source": [
                "sentence_to_feature = dict()\n",
                "sentence_with_no_feature = 0\n",
                "tfidf_sum_sents = np.sum(tfidf_weight, axis=1)\n",
                "print(\"Shape of tf-idf sum: {}\".format(tfidf_sum_sents.shape))\n",
                "for i in range(len(sentence_text_list)):\n",
                "    cur_sent = sentence_text_list[i]\n",
                "    # if this sentence is in the sent_to_id vocabulary\n",
                "    assert cur_sent in sent_to_id\n",
                "    # get the sentence_id (str)\n",
                "    cur_sent_id = sent_to_id[cur_sent]\n",
                "    assert int(cur_sent_id) == i\n",
                "    # find all the feature that has non-zero tf-idf weight\n",
                "    feature_dict = dict()\n",
                "    for j in range(len(tfidf_weight[i])):\n",
                "        if tfidf_weight[i][j] != 0.0:\n",
                "            # get the feature\n",
                "            feature_id = str(j)\n",
                "            feature = feature_word_list[j]\n",
                "            feature_tfidf = tfidf_weight[i][j]\n",
                "            feature_dict[feature_id] = feature_tfidf\n",
                "    if len(feature_dict) > 0:\n",
                "        sentence_to_feature[cur_sent_id] = feature_dict\n",
                "    else:\n",
                "        sentence_with_no_feature += 1\n",
                "    if (i+1) % 50000 == 0:\n",
                "        print(\"Processed {} lines\".format(i+1))\n",
                "print(\"Finish. Totally {} lines\".format(i+1))\n",
                "print(\"Totally {} sentences has at least 1 feature and {} sentences don't have feature.\".format(\n",
                "    len(sentence_to_feature), sentence_with_no_feature))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Shape of tf-idf sum: (740398,)\n",
                        "Processed 50000 lines\n",
                        "Processed 100000 lines\n",
                        "Processed 150000 lines\n",
                        "Processed 200000 lines\n",
                        "Processed 250000 lines\n",
                        "Processed 300000 lines\n",
                        "Processed 350000 lines\n",
                        "Processed 400000 lines\n",
                        "Processed 450000 lines\n",
                        "Processed 500000 lines\n",
                        "Processed 550000 lines\n",
                        "Processed 600000 lines\n",
                        "Processed 650000 lines\n",
                        "Processed 700000 lines\n",
                        "Finish. Totally 740398 lines\n",
                        "Totally 740398 sentences has at least 1 feature and 0 sentences don't have feature.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 125,
            "source": [
                "sentence2feature_filepath = '../Dataset/{}/train/sentence/sentence2feature.json'.format(dataset_name)\n",
                "with open(sentence2feature_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(sentence2feature_filepath))\n",
                "    json.dump(sentence_to_feature, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/sentence/sentence2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 126,
            "source": [
                "sentence_to_feature['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'9': 1.0}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 126
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 127,
            "source": [
                "id_to_sent['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'great location .'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 127
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "source": [
                "id2feature_dict['9']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'location'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 128
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "source": [
                "num_feature_per_sentence = []\n",
                "for key, value in sentence_to_feature.items():\n",
                "    num_feature_per_sentence.append(len(value))\n",
                "    assert len(value) > 0"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "source": [
                "print(\"Mean number of features per sentence: {}\".format(np.mean(num_feature_per_sentence)))\n",
                "print(\"Max number of features per sentence: {}\".format(np.max(num_feature_per_sentence)))\n",
                "print(\"Min number of features per sentence: {}\".format(np.min(num_feature_per_sentence)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of features per sentence: 2.5530457942890177\n",
                        "Max number of features per sentence: 11\n",
                        "Min number of features per sentence: 1\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Get User to Feature"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 131,
            "source": [
                "df_train_data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "        item user  rating                                             review\n",
                            "0          0    0       5  this is our second stay at this hotel ; we sta...\n",
                            "1          1    0       3  small , cramped rooms , moldy grout in shower ...\n",
                            "2         10    0       3  the room doors would slam when guests leave , ...\n",
                            "3        100    0       2  first , the old style tv was on top of the clo...\n",
                            "4       1000    0       5  the food was exceptional - we really enjoyed t...\n",
                            "...      ...  ...     ...                                                ...\n",
                            "205590   752  999       5  the rooms are spacious , quiet , and clean . m...\n",
                            "205591   819  999       5  room was very nice . bed was comfortable , had...\n",
                            "205592   827  999       3  not really the best stay i ever had . room was...\n",
                            "205593   852  999       3  our room was not as nice as i had hoped . the ...\n",
                            "205594   898  999       5  villas are very confortable , spacy and clean ...\n",
                            "\n",
                            "[205595 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>this is our second stay at this hotel ; we sta...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>small , cramped rooms , moldy grout in shower ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>10</td>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the room doors would slam when guests leave , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>100</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>first , the old style tv was on top of the clo...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1000</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the food was exceptional - we really enjoyed t...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205590</th>\n",
                            "      <td>752</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the rooms are spacious , quiet , and clean . m...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205591</th>\n",
                            "      <td>819</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>room was very nice . bed was comfortable , had...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205592</th>\n",
                            "      <td>827</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>not really the best stay i ever had . room was...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205593</th>\n",
                            "      <td>852</td>\n",
                            "      <td>999</td>\n",
                            "      <td>3</td>\n",
                            "      <td>our room was not as nice as i had hoped . the ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>205594</th>\n",
                            "      <td>898</td>\n",
                            "      <td>999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>villas are very confortable , spacy and clean ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>205595 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 131
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## GroupBy User"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 132,
            "source": [
                "group_by_user = df_train_data.groupby('user')\n",
                "user_id_list = []\n",
                "user_reviews = []\n",
                "# Loop over all user\n",
                "for user_df_chunk in list(group_by_user):\n",
                "    user_id = int(user_df_chunk[0])\n",
                "    user_df = user_df_chunk[1]\n",
                "    user_text = \" \".join(list(user_df['review']))\n",
                "    user_id_list.append(user_id)\n",
                "    user_reviews.append(user_text)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 133,
            "source": [
                "print(\"Number of users: {}\".format(len(user_id_list)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of users: 4950\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 134,
            "source": [
                "assert len(user_id_list) == len(user_reviews)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Compute User Tf-idf"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 135,
            "source": [
                "cntvector_user, tfidf_weight_user = get_tfidf_embedding(user_reviews, feature_word_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "source": [
                "check_vocab_is_same(cntvector_user.vocabulary_, feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 136
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 137,
            "source": [
                "tfidf_weight_user.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(4950, 503)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 137
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "source": [
                "print(feature_word_list[:20])"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['room', 'hotel', 'stay', 'staff', 'clean', 'rooms', 'breakfast', 'friendly', 'service', 'location', 'tip', 'comfortable', 'helpful', 'desk', 'front', 'bed', 'food', 'area', 'pool', 'view']\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 139,
            "source": [
                "user_to_feature = dict()\n",
                "for i in range(len(user_id_list)):\n",
                "    feature_dict = dict()\n",
                "    cur_user_id = user_id_list[i]\n",
                "    assert len(tfidf_weight_user[i]) == len(feature_vocab)\n",
                "    for j in range(len(tfidf_weight_user[i])):\n",
                "        if tfidf_weight_user[i][j] != 0.0:\n",
                "            # get the feature\n",
                "            # NOTE: make sure that the feature_id is str format\n",
                "            feature_id = str(j)\n",
                "            feature = feature_word_list[j]\n",
                "            assert feature_vocab[feature] == feature_id\n",
                "            feature_tfidf = tfidf_weight_user[i][j]\n",
                "            feature_dict[feature_id] = feature_tfidf\n",
                "    assert len(feature_dict) > 0\n",
                "    user_to_feature[str(cur_user_id)] = feature_dict\n",
                "    if (i+1) % 1000 == 0:\n",
                "        print(\"{} user processed.\".format(i+1))\n",
                "print(\"Totally {} users\".format(i+1))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1000 user processed.\n",
                        "2000 user processed.\n",
                        "3000 user processed.\n",
                        "4000 user processed.\n",
                        "Totally 4950 users\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "source": [
                "len(user_to_feature)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4950"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 140
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "source": [
                "num_feature_per_user = []\n",
                "for key,value in user_to_feature.items():\n",
                "    num_feature_per_user.append(len(value))\n",
                "    assert len(value) > 0"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "source": [
                "print(\"Mean number of features per user: {}\".format(np.mean(num_feature_per_user)))\n",
                "print(\"Max number of features per user: {}\".format(np.max(num_feature_per_user)))\n",
                "print(\"Min number of features per user: {}\".format(np.min(num_feature_per_user)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of features per user: 137.350101010101\n",
                        "Max number of features per user: 502\n",
                        "Min number of features per user: 17\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 143,
            "source": [
                "len(user_to_feature['1001'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "150"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 143
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Save User to Feature Mapping into Json File"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 144,
            "source": [
                "user2feature_filepath = '../Dataset/{}/train/user/user2feature.json'.format(dataset_name)\n",
                "with open(user2feature_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(user2feature_filepath))\n",
                "    json.dump(user_to_feature, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/user/user2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Get Item to Feature"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## GroupBy Item"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "source": [
                "group_by_item = df_train_data.groupby('item')\n",
                "item_id_list = []\n",
                "item_reviews = []\n",
                "# Loop over all user\n",
                "for item_df_chunk in list(group_by_item):\n",
                "    item_id = str(item_df_chunk[0])\n",
                "    item_df = item_df_chunk[1]\n",
                "    item_text = \" \".join(list(item_df['review']))\n",
                "    item_id_list.append(item_id)\n",
                "    item_reviews.append(item_text)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 147,
            "source": [
                "print(\"Number of items: {}\".format(len(item_id_list)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of items: 4493\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 148,
            "source": [
                "assert len(item_id_list) == len(item_reviews)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Compute Item Tf-idf"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 149,
            "source": [
                "cntvector_item, tfidf_weight_item = get_tfidf_embedding(item_reviews, feature_word_list)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 150,
            "source": [
                "check_vocab_is_same(cntvector_item.vocabulary_, feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 150
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 151,
            "source": [
                "tfidf_weight_item.shape"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "(4493, 503)"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 151
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 152,
            "source": [
                "item_to_feature = dict()\n",
                "for i in range(len(item_id_list)):\n",
                "    feature_dict = dict()\n",
                "    cur_item_id = item_id_list[i]\n",
                "    assert len(tfidf_weight_item[i]) == len(feature_vocab)\n",
                "    for j in range(len(tfidf_weight_item[i])):\n",
                "        if tfidf_weight_item[i][j] != 0.0:\n",
                "            # get the feature\n",
                "            feature_id = str(j)\n",
                "            feature = feature_word_list[j]\n",
                "            assert feature_id == feature_vocab[feature]\n",
                "            feature_tfidf = tfidf_weight_item[i][j]\n",
                "            feature_dict[feature_id] = feature_tfidf\n",
                "    assert len(feature_dict) > 0\n",
                "    item_to_feature[cur_item_id] = feature_dict\n",
                "    if (i+1) % 1000 == 0:\n",
                "        print(\"{} items processed.\".format(i+1))\n",
                "print('Finish. Totally {} items'.format(i+1))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1000 items processed.\n",
                        "2000 items processed.\n",
                        "3000 items processed.\n",
                        "4000 items processed.\n",
                        "Finish. Totally 4493 items\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "source": [
                "len(item_to_feature)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4493"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 153
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "source": [
                "num_feature_per_item = []\n",
                "for key,value in item_to_feature.items():\n",
                "    num_feature_per_item.append(len(value))\n",
                "    assert len(value) > 0"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 155,
            "source": [
                "print(\"Mean number of features per item: {}\".format(np.mean(num_feature_per_item)))\n",
                "print(\"Max number of features per item: {}\".format(np.max(num_feature_per_item)))\n",
                "print(\"Min number of features per item: {}\".format(np.min(num_feature_per_item)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of features per item: 131.53149343423104\n",
                        "Max number of features per item: 363\n",
                        "Min number of features per item: 30\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 156,
            "source": [
                "item2feature_filepath = '../Dataset/{}/train/item/item2feature.json'.format(dataset_name)\n",
                "with open(item2feature_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(item2feature_filepath))\n",
                "    json.dump(item_to_feature, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/tripadvisor/train/item/item2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Compute Top User/Item Features"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "source": [
                "# TODO: Sanity Check"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "73d0647c863cb9ce92fb50b3911519dc6558e38bcfd5798aa86981c2dac43fdf"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}