{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "!which python"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/u/pw7nc/anaconda3/bin/python\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import re\n",
                "import json\n",
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
                "\n",
                "import spacy\n",
                "import nltk\n",
                "from nltk.tokenize import sent_tokenize\n",
                "from spacy.lang.en import English\n",
                "nlp = English()\n",
                "# Create a Tokenizer with the default settings for English\n",
                "# including punctuation rules and exceptions\n",
                "tokenizer = nlp.tokenizer\n",
                "import string\n",
                "punct = string.punctuation\n",
                "from sklearn.feature_extraction import _stop_words"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "dataset_name = \"yelp\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Dataset"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "dir_path = '../Dataset/{}'.format(dataset_name)\n",
                "# Load train dataset\n",
                "train_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'train_review_filtered.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        train_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 100000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading train dataset, totally {} lines.'.format(len(train_review)))\n",
                "# Load test dataset\n",
                "test_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'test_review_filtered_clean.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        test_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 10000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading test dataset, totally {} lines.'.format(len(test_review)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/yelp/train_review_filtered.json\n",
                        "100000 lines loaded.\n",
                        "Finish loading train dataset, totally 191227 lines.\n",
                        "Load file: ../Dataset/yelp/test_review_filtered_clean.json\n",
                        "10000 lines loaded.\n",
                        "20000 lines loaded.\n",
                        "30000 lines loaded.\n",
                        "40000 lines loaded.\n",
                        "Finish loading test dataset, totally 42702 lines.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "df_train_data = pd.DataFrame(train_review, columns=['item', 'user', 'rating', 'review'])\n",
                "df_test_data = pd.DataFrame(test_review, columns=['item', 'user', 'rating', 'review'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "df_train_data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "         item  user  rating                                             review\n",
                            "0        1071  1001       4  place was well lit , very clean , and staff ve...\n",
                            "1       10877  1001       3  the price was great and so was the subs ... th...\n",
                            "2        1114  1001       3  previous i was bundled into a takeout work ord...\n",
                            "3         120  1001       5  this is my favorite restaurant by far . food o...\n",
                            "4        1278  1001       4  nice little gem right here . ok , staff were v...\n",
                            "...       ...   ...     ...                                                ...\n",
                            "191222   4993  9999       5  my two favorites are the carne asada and barba...\n",
                            "191223    704  9999       4  the tacos themselves were a mixed bag . in par...\n",
                            "191224   7379  9999       5                             everything was great .\n",
                            "191225   8530  9999       4  our last experience here went pretty well and ...\n",
                            "191226   8682  9999       5  the surf and turf burrito ( carne asada and sh...\n",
                            "\n",
                            "[191227 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1071</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>place was well lit , very clean , and staff ve...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>10877</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the price was great and so was the subs ... th...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1114</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>3</td>\n",
                            "      <td>previous i was bundled into a takeout work ord...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>120</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>5</td>\n",
                            "      <td>this is my favorite restaurant by far . food o...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1278</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>nice little gem right here . ok , staff were v...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>191222</th>\n",
                            "      <td>4993</td>\n",
                            "      <td>9999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>my two favorites are the carne asada and barba...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>191223</th>\n",
                            "      <td>704</td>\n",
                            "      <td>9999</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the tacos themselves were a mixed bag . in par...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>191224</th>\n",
                            "      <td>7379</td>\n",
                            "      <td>9999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>everything was great .</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>191225</th>\n",
                            "      <td>8530</td>\n",
                            "      <td>9999</td>\n",
                            "      <td>4</td>\n",
                            "      <td>our last experience here went pretty well and ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>191226</th>\n",
                            "      <td>8682</td>\n",
                            "      <td>9999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the surf and turf burrito ( carne asada and sh...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>191227 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# groupby multiple columns\n",
                "groupby_user_item = df_train_data.groupby(['user', 'item'])\n",
                "cnt = 0\n",
                "for key, item in groupby_user_item:\n",
                "    cur_df_user_item = groupby_user_item.get_group(key)\n",
                "    if len(cur_df_user_item) > 1:\n",
                "        if cnt <= 10:\n",
                "            print(cur_df_user_item)\n",
                "        cnt += 1\n",
                "print(\"{} data instance are the same\".format(cnt))\n",
                "# make sure that there are no duplicated reviews"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 data instance are the same\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Sentence2ID and ID2Sentence Mapping"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "sentence2id_filepath = '../Dataset/{}/train/sentence/sentence2id.json'.format(dataset_name)\n",
                "with open(sentence2id_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(sentence2id_filepath))\n",
                "    sent_to_id = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/yelp/train/sentence/sentence2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "type(sent_to_id['good service .'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "str"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 9
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "sent_to_id['good service .']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'13'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "id2sentence_filepath = '../Dataset/{}/train/sentence/id2sentence.json'.format(dataset_name)\n",
                "with open(id2sentence_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(id2sentence_filepath))\n",
                "    id_to_sent = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/yelp/train/sentence/id2sentence.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "id_to_sent['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'service was good .'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 12
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "assert len(sent_to_id) == len(id_to_sent)\n",
                "print(\"Number of sentence (with feature) on train set: {}\".format(len(sent_to_id)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of sentence (with feature) on train set: 492739\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Feature Words"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "feature2id_filepath = '../Dataset/{}/train/feature/feature2id.json'.format(dataset_name)\n",
                "with open(feature2id_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(feature2id_filepath))\n",
                "    feature_vocab = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/yelp/train/feature/feature2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "len(feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "498"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "feature_vocab['wifi']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'371'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Sentence2Feature"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "sentence2feature_filepath = '../Dataset/{}/train/sentence/sentence2feature.json'.format(dataset_name)\n",
                "with open(sentence2feature_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(sentence2feature_filepath))\n",
                "    sentence_to_feature = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/yelp/train/sentence/sentence2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "sentence_to_feature['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'1': 1.0}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "assert len(sentence_to_feature) == len(sent_to_id)\n",
                "len(sentence_to_feature)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "492739"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construct User-Item Pair"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## GrounpBy User"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "group_by_user = df_train_data.groupby('user')\n",
                "group_by_user_dict = dict(tuple(group_by_user))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "group_by_user_dict['1001']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "     item  user  rating                                             review\n",
                            "0    1071  1001       4  place was well lit , very clean , and staff ve...\n",
                            "1   10877  1001       3  the price was great and so was the subs ... th...\n",
                            "2    1114  1001       3  previous i was bundled into a takeout work ord...\n",
                            "3     120  1001       5  this is my favorite restaurant by far . food o...\n",
                            "4    1278  1001       4  nice little gem right here . ok , staff were v...\n",
                            "..    ...   ...     ...                                                ...\n",
                            "81   9121  1001       4  for a waffle house this place is a little bett...\n",
                            "82   9203  1001       1             ++ the chips were good , salsa eh, , ,\n",
                            "83   9307  1001       4             food was very good and great price , ,\n",
                            "84   9507  1001       5  awesome menu options , large sized menu is pre...\n",
                            "85   9519  1001       4  atmosphere , is pretty great , and the live mu...\n",
                            "\n",
                            "[86 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1071</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>place was well lit , very clean , and staff ve...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>10877</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the price was great and so was the subs ... th...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1114</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>3</td>\n",
                            "      <td>previous i was bundled into a takeout work ord...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>120</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>5</td>\n",
                            "      <td>this is my favorite restaurant by far . food o...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1278</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>nice little gem right here . ok , staff were v...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>81</th>\n",
                            "      <td>9121</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>for a waffle house this place is a little bett...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82</th>\n",
                            "      <td>9203</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>1</td>\n",
                            "      <td>++ the chips were good , salsa eh, , ,</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>83</th>\n",
                            "      <td>9307</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>food was very good and great price , ,</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>84</th>\n",
                            "      <td>9507</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>5</td>\n",
                            "      <td>awesome menu options , large sized menu is pre...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>85</th>\n",
                            "      <td>9519</td>\n",
                            "      <td>1001</td>\n",
                            "      <td>4</td>\n",
                            "      <td>atmosphere , is pretty great , and the live mu...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>86 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "len(group_by_user_dict)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4604"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 23
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "user_id_list = list(df_train_data['user'].unique())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "print(len(user_id_list))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "4604\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "user_to_sent = dict()\n",
                "cnt_sentence_with_no_feature = 0\n",
                "\n",
                "for user_id in user_id_list:\n",
                "    # note this user_id is a str\n",
                "    # get the dataframe for this user\n",
                "    user_df = group_by_user_dict[user_id]\n",
                "    user_reviews = list(user_df['review'])\n",
                "    user_sent_ids = set()\n",
                "    for review in user_reviews:\n",
                "        # tokenize this review (i.e. split into sentences)\n",
                "        review_sents = sent_tokenize(review)\n",
                "        # check whether the sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                # assert cur_sent_id in sentence_to_feature\n",
                "                # user_sent_ids.add(cur_sent_id)\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of this user\n",
                "                    user_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    cnt_sentence_with_no_feature += 1\n",
                "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
                "    if len(user_sent_ids) == 0:\n",
                "        print(\"User: {} has no effective sentences, skip it.\".format(user_id))\n",
                "    else:\n",
                "        user_to_sent[user_id] = user_sent_ids\n",
                "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 sentence with no feature\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "len(user_to_sent)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4604"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 27
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "user_to_sentids = dict()\n",
                "for user_id, user_sents in user_to_sent.items():\n",
                "    assert len(user_sents) > 0\n",
                "    assert isinstance(user_id, str)\n",
                "    assert isinstance(list(user_sents)[0], str)\n",
                "    user_to_sentids[user_id] = list(user_sents)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "len(user_to_sentids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4604"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 29
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "user2sentids_filepath = '../Dataset/{}/train/user/user2sentids.json'.format(dataset_name)\n",
                "with open(user2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(user2sentids_filepath))\n",
                "    json.dump(user_to_sentids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/yelp/train/user/user2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "source": [
                "user_side_cdd_sents_num = list()\n",
                "for key, value in user_to_sentids.items():\n",
                "    user_side_cdd_sents_num.append(len(value))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "print(\"Mean number of sentence per user: {}\".format(\n",
                "    np.mean(user_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Min number of sentence per user: {}\".format(\n",
                "    np.min(user_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Max number of sentence per user: {}\".format(\n",
                "    np.max(user_side_cdd_sents_num)\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of sentence per user: 111.28996524761077\n",
                        "Min number of sentence per user: 18\n",
                        "Max number of sentence per user: 1756\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "source": [
                "print(\"Top-10 least numbber of sentences per user: {}\".format(\n",
                "    sorted(user_side_cdd_sents_num)[:10]\n",
                "))\n",
                "print(\"Top-10 most numbber of sentences per user: {}\".format(\n",
                "    sorted(user_side_cdd_sents_num)[-10:]\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Top-10 least numbber of sentences per user: [18, 18, 19, 20, 21, 21, 21, 21, 21, 22]\n",
                        "Top-10 most numbber of sentences per user: [946, 970, 999, 1000, 1037, 1074, 1274, 1421, 1550, 1756]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## GroupBy Item"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "source": [
                "group_by_item = df_train_data.groupby('item')\n",
                "group_by_item_dict = dict(tuple(group_by_item))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "source": [
                "group_by_item_dict['1267']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "        item   user  rating                                             review\n",
                            "7006    1267   1103       5  service was quick and very attentive . the muf...\n",
                            "8846    1267  11259       5  dineen coffee co is a sleek and modern coffee ...\n",
                            "23902   1267   1376       4  the pistachio bread was surprisingly soft like...\n",
                            "25199   1267    140       4  coffee was amazing , by amazing i mean i would...\n",
                            "28184   1267    147       4  the staff are very nice and very accommodating...\n",
                            "30670   1267   1519       5             nice patio . limited outdoor seating .\n",
                            "31802   1267   1547       4  their espresso blend was delicious , strong bu...\n",
                            "32245   1267   1564       4  my coffee was as high quality as is to be expe...\n",
                            "46910   1267    196       3  downtown toronto on a sunday morning is a ghos...\n",
                            "47230   1267   1967       3  but the atmosphere is lovely . cute spot for c...\n",
                            "51691   1267   2110       5  coffee - real coffee , americano , latte , and...\n",
                            "63512   1267   2463       3  the atmosphere of this place is beautiful beca...\n",
                            "75789   1267   2859       4  adorable cafe , but who can stay indoors with ...\n",
                            "91701   1267   3448       4  came here for their coffee and beans to go 2 m...\n",
                            "98972   1267   3733       2  the service was friendly just the coffee i fin...\n",
                            "102738  1267   3896       4  beautiful patio outside when it s a nice day b...\n",
                            "105078  1267     40       4  the sandwich was soft and delicious and the ba...\n",
                            "121349  1267    479       5  delicious food , quick and friendly service , ...\n",
                            "133002  1267   5345       5  the ambiance is beautiful and reminds me of a ...\n",
                            "149039  1267     63       4  this is quite a busy cafe , which is not surpr...\n",
                            "157636  1267    693       3  the cafe is located on temperance street . lat...\n",
                            "162077  1267   7257       4  the iced tea was n't anything too special that...\n",
                            "178627  1267    869       4  their interior is nice with their cute tiles a...\n",
                            "181136  1267    897       4  staff is skilled and efficient , which is need...\n",
                            "185737  1267   9408       4  i do find that their pastries are a bit pricey...\n",
                            "187705  1267    958       4                          excellent latte and tea .\n",
                            "190366  1267    990       4  the drink was quite pricey at $ 4.75 ( $ 5.05 ..."
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>7006</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1103</td>\n",
                            "      <td>5</td>\n",
                            "      <td>service was quick and very attentive . the muf...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8846</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>11259</td>\n",
                            "      <td>5</td>\n",
                            "      <td>dineen coffee co is a sleek and modern coffee ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>23902</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1376</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the pistachio bread was surprisingly soft like...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>25199</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>140</td>\n",
                            "      <td>4</td>\n",
                            "      <td>coffee was amazing , by amazing i mean i would...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>28184</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>147</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the staff are very nice and very accommodating...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>30670</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1519</td>\n",
                            "      <td>5</td>\n",
                            "      <td>nice patio . limited outdoor seating .</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>31802</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1547</td>\n",
                            "      <td>4</td>\n",
                            "      <td>their espresso blend was delicious , strong bu...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>32245</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1564</td>\n",
                            "      <td>4</td>\n",
                            "      <td>my coffee was as high quality as is to be expe...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>46910</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>196</td>\n",
                            "      <td>3</td>\n",
                            "      <td>downtown toronto on a sunday morning is a ghos...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>47230</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>1967</td>\n",
                            "      <td>3</td>\n",
                            "      <td>but the atmosphere is lovely . cute spot for c...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>51691</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>2110</td>\n",
                            "      <td>5</td>\n",
                            "      <td>coffee - real coffee , americano , latte , and...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>63512</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>2463</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the atmosphere of this place is beautiful beca...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75789</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>2859</td>\n",
                            "      <td>4</td>\n",
                            "      <td>adorable cafe , but who can stay indoors with ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>91701</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>3448</td>\n",
                            "      <td>4</td>\n",
                            "      <td>came here for their coffee and beans to go 2 m...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>98972</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>3733</td>\n",
                            "      <td>2</td>\n",
                            "      <td>the service was friendly just the coffee i fin...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>102738</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>3896</td>\n",
                            "      <td>4</td>\n",
                            "      <td>beautiful patio outside when it s a nice day b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>105078</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>40</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the sandwich was soft and delicious and the ba...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>121349</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>479</td>\n",
                            "      <td>5</td>\n",
                            "      <td>delicious food , quick and friendly service , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>133002</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>5345</td>\n",
                            "      <td>5</td>\n",
                            "      <td>the ambiance is beautiful and reminds me of a ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>149039</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>63</td>\n",
                            "      <td>4</td>\n",
                            "      <td>this is quite a busy cafe , which is not surpr...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>157636</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>693</td>\n",
                            "      <td>3</td>\n",
                            "      <td>the cafe is located on temperance street . lat...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>162077</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>7257</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the iced tea was n't anything too special that...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>178627</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>869</td>\n",
                            "      <td>4</td>\n",
                            "      <td>their interior is nice with their cute tiles a...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>181136</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>897</td>\n",
                            "      <td>4</td>\n",
                            "      <td>staff is skilled and efficient , which is need...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>185737</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>9408</td>\n",
                            "      <td>4</td>\n",
                            "      <td>i do find that their pastries are a bit pricey...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>187705</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>958</td>\n",
                            "      <td>4</td>\n",
                            "      <td>excellent latte and tea .</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>190366</th>\n",
                            "      <td>1267</td>\n",
                            "      <td>990</td>\n",
                            "      <td>4</td>\n",
                            "      <td>the drink was quite pricey at $ 4.75 ( $ 5.05 ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 35
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "source": [
                "len(group_by_item_dict)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "7837"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 36
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "source": [
                "item_id_list = list(df_train_data['item'].unique())\n",
                "item_to_sent = dict()\n",
                "cnt_sentence_with_no_feature = 0\n",
                "for item_id in item_id_list:\n",
                "    # note this item_id is a str\n",
                "    # get the dataframe for this item\n",
                "    assert isinstance(item_id, str)\n",
                "    item_df = group_by_item_dict[item_id]\n",
                "    item_reviews = list(item_df['review'])\n",
                "    item_sent_ids = set()\n",
                "    for review in item_reviews:\n",
                "        # tokenize this review (i.e. split into sentences)\n",
                "        review_sents = sent_tokenize(review)\n",
                "        # check whether the sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of this user\n",
                "                    item_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    cnt_sentence_with_no_feature += 1\n",
                "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
                "    if len(item_sent_ids) == 0:\n",
                "        print(\"Item {} has no effective sentence, skip it.\".format(item_id))\n",
                "    else:\n",
                "        item_to_sent[item_id] = item_sent_ids\n",
                "\n",
                "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 sentence with no feature\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "source": [
                "len(item_to_sent)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "7837"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 38
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "source": [
                "item_to_sentids = dict()\n",
                "for item_id, item_sents in item_to_sent.items():\n",
                "    assert len(item_sents) > 0\n",
                "    assert isinstance(list(item_sents)[0], str)\n",
                "    item_to_sentids[item_id] = list(item_sents)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "len(item_to_sentids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "7837"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 40
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "source": [
                "item2sentids_filepath = '../Dataset/{}/train/item/item2sentids.json'.format(dataset_name)\n",
                "with open(item2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(item2sentids_filepath))\n",
                "    json.dump(item_to_sentids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/yelp/train/item/item2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "item_side_cdd_sents_num = list()\n",
                "for key, value in item_to_sentids.items():\n",
                "    item_side_cdd_sents_num.append(len(value))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "print(\"Mean number of sentence per item: {}\".format(\n",
                "    np.mean(item_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Min number of sentence per item: {}\".format(\n",
                "    np.min(item_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Max number of sentence per item: {}\".format(\n",
                "    np.max(item_side_cdd_sents_num)\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of sentence per item: 65.58683169580196\n",
                        "Min number of sentence per item: 5\n",
                        "Max number of sentence per item: 625\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "print(\"Top-10 least numbber of sentence per item: {}\".format(\n",
                "    sorted(item_side_cdd_sents_num)[:10]\n",
                "))\n",
                "print(\"Top-10 most numbber of sentence per item: {}\".format(\n",
                "    sorted(item_side_cdd_sents_num)[-10:]\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Top-10 least numbber of sentence per item: [5, 7, 7, 7, 8, 8, 8, 8, 8, 8]\n",
                        "Top-10 most numbber of sentence per item: [455, 457, 457, 471, 473, 512, 540, 550, 579, 625]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# For Each Data Instance in TrainSet"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "import random\n",
                "sample_sent_num = 500\n",
                "user_item_candidate_sent_ids = dict()\n",
                "# Loop over all User\n",
                "user_cnt = 0\n",
                "review_cnt = 0\n",
                "review_with_no_selectd_label_sentence = 0\n",
                "useable_review_cnt = 0\n",
                "sentence_with_no_feature_cnt = 0\n",
                "sentence_not_tracked = set()\n",
                "for user_df_chunk in list(group_by_user):\n",
                "    user_id = int(user_df_chunk[0])\n",
                "    user_id_str = str(user_df_chunk[0])\n",
                "    user_df = user_df_chunk[1]\n",
                "    # get user sents\n",
                "    cur_user_sent_ids = user_to_sent[user_id_str]\n",
                "    # item-level dict\n",
                "    item_candidate_sent_ids = dict()\n",
                "    for idx, row in user_df.iterrows():\n",
                "        item_id = int(row['item'])\n",
                "        item_id_str = str(row['item'])\n",
                "        review_text = row['review']\n",
                "        review_cnt += 1\n",
                "        # get item sents\n",
                "        cur_item_sent_ids = item_to_sent[item_id_str]\n",
                "        # get review_text's sent ids\n",
                "        cur_review_sent_ids = set()\n",
                "        ## tokenize this review\n",
                "        review_sents = sent_tokenize(review_text)\n",
                "        ## check whether this sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of current review\n",
                "                    cur_review_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    sentence_with_no_feature_cnt += 1\n",
                "            else:\n",
                "                # if this sentence is not being tracked by the sentence-id mapping\n",
                "                # we add it into this set to see how many sentences are being ignored\n",
                "                sentence_not_tracked.add(sent)\n",
                "        ## check whether the true label of the sentence is an empty list of sent_ids\n",
                "        if len(cur_review_sent_ids) == 0:\n",
                "            review_with_no_selectd_label_sentence += 1\n",
                "        else:\n",
                "            # construct the candidate set which is an union of user sentences and item sentences\n",
                "            cur_useritem_sent_ids = cur_user_sent_ids | cur_item_sent_ids\n",
                "            # sample some sentences\n",
                "            if len(cur_useritem_sent_ids) > sample_sent_num:\n",
                "                sample_useritem_sent_ids = set(random.sample(cur_useritem_sent_ids, sample_sent_num))\n",
                "            else:\n",
                "                sample_useritem_sent_ids = cur_useritem_sent_ids\n",
                "            # union sampled sentences with true labeled sentences\n",
                "            final_useritem_sent_ids = sample_useritem_sent_ids | cur_review_sent_ids\n",
                "            # add this into the dict\n",
                "            item_candidate_sent_ids[item_id_str] = [list(final_useritem_sent_ids), list(cur_review_sent_ids)]\n",
                "            # add useable review cnt\n",
                "            useable_review_cnt += 1\n",
                "    if len(item_candidate_sent_ids) == 0:\n",
                "        print(\"User: {} has no useful item, skip this user ...\".format(user_id_str))\n",
                "    else:\n",
                "        # add the item_candidate_sent_ids dict into the user-level dict\n",
                "        user_item_candidate_sent_ids[user_id_str] = item_candidate_sent_ids\n",
                "    user_cnt += 1\n",
                "    if user_cnt % 1000 == 0:\n",
                "        print(\"{} user processed\".format(user_cnt))\n",
                "\n",
                "print('Finish.')\n",
                "print('Totally {} users'.format(user_cnt))\n",
                "print('Totally {0} reviews. Among them {1} reviews has empty true label sentence'.format(\n",
                "    review_cnt, review_with_no_selectd_label_sentence))\n",
                "print(\"{} sentences has 0 feature\".format(sentence_with_no_feature_cnt))\n",
                "print(\"{} sentences are not being tracked in the sent2id mapping\".format(len(sentence_not_tracked)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "1000 user processed\n",
                        "2000 user processed\n",
                        "3000 user processed\n",
                        "4000 user processed\n",
                        "Finish.\n",
                        "Totally 4604 users\n",
                        "Totally 191227 reviews. Among them 0 reviews has empty true label sentence\n",
                        "0 sentences has 0 feature\n",
                        "929 sentences are not being tracked in the sent2id mapping\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "len(user_item_candidate_sent_ids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "4604"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 46
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "# let's check how many unique reviews are there\n",
                "\n",
                "cnt_unique_reviews = 0\n",
                "cnt_empty_true_sent = 0\n",
                "sentence_per_review = []\n",
                "candidate_sentence_num_cnt_per_review = []\n",
                "# [user-level] Loop for each user\n",
                "for user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "    user_id_str = str(user_chunk[0])\n",
                "    # assert isinstance(user_chunk[0], str)\n",
                "    # [item-level] Loop for each user-item pair\n",
                "    user_item_chunks = list(user_chunk[1].items())\n",
                "    for item_chunk in user_item_chunks:\n",
                "        item_id_str = str(item_chunk[0])\n",
                "        # assert isinstance(item_chunk[0], str)\n",
                "        candidate_sent_ids = item_chunk[1][0]\n",
                "        true_sent_ids = item_chunk[1][1]\n",
                "        if len(true_sent_ids) == 0:\n",
                "            cnt_empty_true_sent += 1\n",
                "        else:\n",
                "            assert isinstance(candidate_sent_ids[0], str)\n",
                "            assert isinstance(true_sent_ids[0], str)\n",
                "            # make sure that all true label sent_ids appears in the corresponding candidate set\n",
                "            for true_sent_id in true_sent_ids:\n",
                "                assert true_sent_id in candidate_sent_ids\n",
                "            sentence_per_review.append(len(true_sent_ids))\n",
                "            candidate_sentence_num_cnt_per_review.append(len(candidate_sent_ids))\n",
                "        cnt_unique_reviews += 1\n",
                "\n",
                "print(\"Total number of unique selected reviews: {}\".format(cnt_unique_reviews))\n",
                "print(\"Total number of review with empty true sentences: {}\".format(cnt_empty_true_sent))\n",
                "print(\"Total number of unique review with non-empty true sentences: {}\".format(\n",
                "    cnt_unique_reviews - cnt_empty_true_sent))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Total number of unique selected reviews: 191227\n",
                        "Total number of review with empty true sentences: 0\n",
                        "Total number of unique review with non-empty true sentences: 191227\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "print(\"Totally {} user-item pairs in the trainset\".format(len(sentence_per_review)))\n",
                "print(\"max number of true sentence per review: {}\".format(np.max(sentence_per_review)))\n",
                "print(\"min number of true sentence per review: {}\".format(np.min(sentence_per_review)))\n",
                "print(\"mean number of true sentence per review: {}\".format(np.mean(sentence_per_review)))\n",
                "print(\"max number of candidate sentence per review: {}\".format(np.max(candidate_sentence_num_cnt_per_review)))\n",
                "print(\"min number of candidate sentence per review: {}\".format(np.min(candidate_sentence_num_cnt_per_review)))\n",
                "print(\"mean number of candidate sentence per review: {}\".format(np.mean(candidate_sentence_num_cnt_per_review)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Totally 191227 user-item pairs in the trainset\n",
                        "max number of true sentence per review: 23\n",
                        "min number of true sentence per review: 1\n",
                        "mean number of true sentence per review: 2.68899266316995\n",
                        "max number of candidate sentence per review: 520\n",
                        "min number of candidate sentence per review: 32\n",
                        "mean number of candidate sentence per review: 270.1224931625764\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "useritem2sentids_filepath = '../Dataset/{}/train/useritem2sentids.json'.format(dataset_name)\n",
                "with open(useritem2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(useritem2sentids_filepath))\n",
                "    json.dump(user_item_candidate_sent_ids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/yelp/train/useritem2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "source": [
                "example_user_id = '1001'\n",
                "example_item_id = '1278'\n",
                "print(\"User: {0}\\tItem: {1}\".format(example_user_id, example_item_id))\n",
                "print(\n",
                "    \"Number of (sampled) cdd sents: \", \n",
                "    len(user_item_candidate_sent_ids[example_user_id][example_item_id][0]))\n",
                "print(\"Number of user side cdd sents:\", len(user_to_sent[example_user_id]))\n",
                "print(\"Number of item side cdd sents:\", len(item_to_sent[example_item_id]))\n",
                "print(\"Number of GT sentences: \", \n",
                "    len(user_item_candidate_sent_ids[example_user_id][example_item_id][1]))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "User: 1001\tItem: 1278\n",
                        "Number of (sampled) cdd sents:  220\n",
                        "Number of user side cdd sents: 139\n",
                        "Number of item side cdd sents: 84\n",
                        "Number of GT sentences:  3\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "for sent_id in user_item_candidate_sent_ids[example_user_id][example_item_id][1]:\n",
                "    assert sent_id in user_item_candidate_sent_ids[example_user_id][example_item_id][0]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Write train useritem_cdd in a line-by-line format"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "source": [
                "# Write useritem2sentids into a line-by-line format\n",
                "train_useritem2sentid_multiline_file = '../Dataset/{}/train/useritem2sentids_multilines.json'.format(dataset_name)\n",
                "if os.path.exists(train_useritem2sentid_multiline_file):\n",
                "    print(\"File: {} exists, remove it.\".format(train_useritem2sentid_multiline_file))\n",
                "    os.remove(train_useritem2sentid_multiline_file)\n",
                "else:\n",
                "    print(\"File: {} doesn't exist, creat it.\".format(train_useritem2sentid_multiline_file))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "File: ../Dataset/yelp/train/useritem2sentids_multilines.json doesn't exist, creat it.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "source": [
                "with open(train_useritem2sentid_multiline_file, 'a') as f1:\n",
                "    print(\"Write file: {}\".format(train_useritem2sentid_multiline_file))\n",
                "    cnt_user = 0\n",
                "    cnt_review = 0\n",
                "    user_set = set()\n",
                "    item_set = set()\n",
                "    useritem_set = set()\n",
                "    for trainset_user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "        assert isinstance(trainset_user_chunk[0], str)\n",
                "        user_id_str = trainset_user_chunk[0]\n",
                "        user_id = int(trainset_user_chunk[0])\n",
                "        user_item_chunks = list(trainset_user_chunk[1].items())\n",
                "        for item_chunk in user_item_chunks:\n",
                "            assert isinstance(item_chunk[0], str)\n",
                "            item_id_str = item_chunk[0]\n",
                "            item_id = int(item_chunk[0])\n",
                "            candidate_sent_ids = item_chunk[1][0]\n",
                "            gold_revw_sent_ids = item_chunk[1][1]\n",
                "            assert isinstance(candidate_sent_ids, list)\n",
                "            assert isinstance(gold_revw_sent_ids, list)\n",
                "            assert isinstance(candidate_sent_ids[0], str)\n",
                "            assert isinstance(gold_revw_sent_ids[0], str)\n",
                "            for cur_id in gold_revw_sent_ids:\n",
                "                assert cur_id in candidate_sent_ids\n",
                "            cur_data_dict = {'user_id': user_id_str, 'item_id': item_id_str, 'candidate': candidate_sent_ids, \"review\": gold_revw_sent_ids}\n",
                "            # write this into the json file\n",
                "            json.dump(cur_data_dict, f1)\n",
                "            f1.write(\"\\n\")\n",
                "            cnt_review += 1\n",
                "            useritem_set.add((user_id_str, item_id_str))\n",
                "            item_set.add(item_id_str)\n",
                "            if cnt_review % 50000 == 0:\n",
                "                print(\"{} lines of train data written.\".format(cnt_review))\n",
                "        cnt_user += 1\n",
                "        user_set.add(user_id_str)\n",
                "\n",
                "assert cnt_user == len(user_set)\n",
                "assert cnt_review == len(useritem_set)\n",
                "print(\"Totally {} users\".format(cnt_user))\n",
                "print(\"Totally {} items\".format(len(item_set)))\n",
                "print(\"Totally {} reviews\".format(cnt_review))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/yelp/train/useritem2sentids_multilines.json\n",
                        "50000 lines of train data written.\n",
                        "100000 lines of train data written.\n",
                        "150000 lines of train data written.\n",
                        "200000 lines of train data written.\n",
                        "250000 lines of train data written.\n",
                        "300000 lines of train data written.\n",
                        "350000 lines of train data written.\n",
                        "Totally 9209 users\n",
                        "Totally 7837 items\n",
                        "Totally 390092 reviews\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "source": [
                "!head -n 1 '../Dataset/yelp/train/useritem2sentids_multilines.json'"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{\"user_id\": \"100\", \"item_id\": \"10\", \"candidate\": [\"863149\", \"666509\", \"984394\", \"833935\", \"852909\", \"14132\", \"8785\", \"14000\", \"14059\", \"81140\", \"14245\", \"426338\", \"13992\", \"14198\", \"221648\", \"14113\", \"701274\", \"666508\", \"763813\", \"999832\", \"14189\", \"704224\", \"673678\", \"686221\", \"101430\", \"294554\", \"800076\", \"14377\", \"14307\", \"14317\", \"629934\", \"14216\", \"819225\", \"661419\", \"96122\", \"360284\", \"14278\", \"212477\", \"836672\", \"913853\", \"602175\", \"14009\", \"14400\", \"419017\", \"14370\", \"956226\", \"14405\", \"449351\", \"714568\", \"684\", \"7461\", \"536603\", \"838144\", \"984395\", \"14103\", \"567430\", \"13981\", \"14380\", \"166273\", \"25049\", \"405317\", \"13983\", \"14280\", \"14133\", \"247\", \"14244\", \"14262\", \"838143\", \"381720\", \"106626\", \"109570\", \"109573\", \"220726\", \"14116\", \"55446\", \"617655\", \"14217\", \"14269\", \"14381\", \"14253\", \"14023\", \"14312\", \"14291\", \"653961\", \"14337\", \"14051\", \"14165\", \"991184\", \"913852\", \"389741\", \"271064\", \"38318\", \"541965\", \"14061\", \"14210\", \"753562\", \"14238\", \"732857\", \"178085\", \"14248\", \"351419\", \"836670\", \"859833\", \"14193\", \"315560\", \"161612\", \"14324\", \"14199\", \"266725\", \"14283\", \"13984\", \"14205\", \"560981\", \"382781\", \"265383\", \"14095\", \"316038\", \"349873\", \"14002\", \"14068\", \"14230\", \"576711\", \"69912\", \"419018\", \"496841\", \"14149\", \"349874\", \"122242\", \"215539\", \"14079\", \"268003\", \"14218\", \"273020\", \"81143\", \"524290\", \"14290\", \"212311\", \"630111\", \"14300\", \"831795\", \"13978\", \"14301\", \"351418\", \"14065\", \"855442\", \"714569\", \"14030\", \"905664\", \"434330\", \"14225\", \"653964\", \"512625\", \"165545\", \"609775\", \"8865\", \"14022\", \"449262\", \"14013\", \"728716\", \"418950\", \"292592\", \"933309\", \"14206\", \"405544\", \"823831\", \"14147\", \"14020\", \"14156\", \"191408\", \"732858\", \"14354\", \"45062\", \"14368\", \"931448\", \"14376\", \"14078\", \"709852\", \"630110\", \"467639\", \"14394\", \"14018\", \"629935\", \"818686\", \"633685\", \"186463\", \"837757\", \"767267\", \"14231\", \"360945\", \"171022\", \"14229\", \"290788\", \"838314\", \"609776\", \"530551\", \"14362\", \"14105\", \"14204\", \"136297\", \"558836\", \"530552\", \"633690\", \"14008\", \"289783\", \"723512\", \"696400\", \"14086\", \"5885\", \"165544\", \"14288\", \"14366\", \"14184\", \"14254\", \"140197\", \"991181\", \"398058\", \"449350\", \"252569\", \"999833\", \"728717\", \"14112\", \"14391\", \"14115\", \"3527\", \"14330\", \"743351\", \"14010\", \"443863\", \"271063\", \"918208\", \"14109\", \"933310\", \"360948\", \"374157\", \"14114\", \"541968\", \"174331\", \"735666\", \"398820\", \"14226\", \"14388\", \"14353\", \"14096\", \"14329\", \"560652\", \"14219\", \"999169\", \"736302\", \"5884\", \"29234\", \"321859\", \"183\", \"14364\", \"476058\", \"14319\", \"465127\", \"14214\", \"14108\", \"13993\", \"14346\", \"81142\", \"186465\", \"290789\", \"88137\", \"560654\", \"574766\", \"14383\", \"14170\", \"333150\", \"833936\", \"704389\", \"711139\", \"51998\", \"749802\", \"272915\", \"14104\", \"339173\", \"14287\", \"14140\", \"541969\", \"212312\", \"14016\", \"529957\", \"588679\", \"360947\", \"14042\", \"696228\", \"915787\", \"14123\", \"426339\", \"351415\", \"14347\", \"252568\", \"14395\", \"14296\", \"14309\", \"653963\", \"14076\", \"13990\", \"351416\", \"14139\", \"613323\", \"515453\", \"14390\", \"14054\", \"14250\", \"351413\", \"623138\", \"178083\", \"14263\", \"14372\", \"14408\", \"818685\", \"136298\", \"596129\", \"818684\", \"339169\", \"14285\", \"292595\", \"722310\", \"14137\", \"14185\", \"541966\", \"212476\", \"852979\", \"282171\", \"14134\", \"14302\", \"918211\", \"936781\", \"696803\", \"689331\", \"695048\", \"14175\", \"13997\", \"14033\", \"360283\", \"598320\", \"770053\", \"14131\", \"576710\", \"513069\", \"13979\", \"14102\", \"14241\", \"748775\", \"14082\", \"14074\", \"915377\", \"14266\", \"14406\", \"339174\", \"830339\", \"13982\", \"838315\", \"14213\", \"365190\", \"104238\", \"14310\", \"14352\", \"14235\", \"14167\", \"161613\", \"704388\", \"220725\", \"14067\", \"14289\", \"421704\", \"18683\", \"109574\", \"819226\", \"14128\", \"215923\", \"14060\", \"14386\", \"792924\", \"14151\", \"551191\", \"14281\", \"597\", \"728718\", \"14340\", \"14385\", \"14001\", \"14178\", \"45136\", \"308078\", \"14176\", \"14273\", \"137463\", \"116060\", \"936780\", \"421706\", \"333151\", \"14293\", \"14006\", \"631424\", \"14072\", \"633692\", \"836673\", \"855441\", \"630114\", \"14260\", \"14305\", \"14365\", \"14344\", \"915786\", \"178082\", \"14303\", \"14032\", \"88135\", \"14371\", \"14106\", \"560653\", \"14127\", \"14081\", \"14350\", \"722309\", \"43316\", \"14097\", \"916999\", \"748774\", \"14212\", \"686218\", \"576708\", \"333153\", \"877829\", \"14186\", \"14163\", \"321861\", \"621461\", \"278246\", \"104236\", \"137464\", \"51999\", \"560651\", \"886357\", \"101431\", \"14274\", \"204139\", \"763814\", \"14332\", \"14215\", \"502\", \"14195\", \"14063\", \"685069\", \"1457\", \"349872\", \"674281\", \"823832\", \"14094\", \"541964\", \"1002027\", \"14179\", \"2462\", \"14027\", \"685068\", \"797667\", \"45061\", \"433790\", \"265382\", \"8402\", \"161610\", \"823834\", \"14351\", \"102536\", \"496216\", \"14168\", \"884409\", \"382131\", \"292593\", \"14265\", \"14087\", \"817544\", \"14150\", \"399429\", \"425527\", \"142564\", \"686219\", \"433791\", \"13980\", \"88136\", \"14012\", \"254906\", \"936347\", \"292594\", \"252567\", \"351417\", \"81141\", \"14331\", \"14028\", \"14367\", \"14066\", \"836960\", \"48292\", \"104237\", \"724636\", \"14124\", \"772170\", \"14014\", \"14144\"], \"review\": [\"13978\", \"13979\", \"13981\", \"13980\"]}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Save User-Item Pairs (Train Set)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "source": [
                "user_item_pairs = dict()\n",
                "cnt_user_item_pairs = 0\n",
                "for trainset_user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "    assert isinstance(trainset_user_chunk[0], str)\n",
                "    user_id_str = trainset_user_chunk[0]\n",
                "    user_item_chunks = list(trainset_user_chunk[1].items())\n",
                "    assert user_id_str not in user_item_pairs\n",
                "    user_item_pairs[user_id_str] = list()\n",
                "    for item_chunk in user_item_chunks:\n",
                "        assert isinstance(item_chunk[0], str)\n",
                "        item_id_str = item_chunk[0]\n",
                "        assert item_id_str not in user_item_pairs[user_id_str]\n",
                "        user_item_pairs[user_id_str].append(item_id_str)\n",
                "        cnt_user_item_pairs += 1\n",
                "print(\"Total number of user-item pair on trainset: {}\".format(cnt_user_item_pairs))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Total number of user-item pair on trainset: 390092\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "source": [
                "train_useritempairs_file = '../Dataset/{}/train/useritem_pairs.json'.format(dataset_name)\n",
                "with open(train_useritempairs_file, 'w') as f:\n",
                "    print(\"write file: {}\".format(train_useritempairs_file))\n",
                "    json.dump(user_item_pairs, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "write file: ../Dataset/yelp/train/useritem_pairs.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "73d0647c863cb9ce92fb50b3911519dc6558e38bcfd5798aa86981c2dac43fdf"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}