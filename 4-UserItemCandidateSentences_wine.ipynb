{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "!which python"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/u/pw7nc/anaconda3/bin/python\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import re\n",
                "import json\n",
                "import os\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.preprocessing import normalize\n",
                "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
                "\n",
                "import spacy\n",
                "import nltk\n",
                "from nltk.tokenize import sent_tokenize\n",
                "from spacy.lang.en import English\n",
                "nlp = English()\n",
                "# Create a Tokenizer with the default settings for English\n",
                "# including punctuation rules and exceptions\n",
                "tokenizer = nlp.tokenizer\n",
                "import string\n",
                "punct = string.punctuation\n",
                "from sklearn.feature_extraction import _stop_words"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "dataset_name = \"wine\""
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Dataset"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "dir_path = '../Dataset/{}'.format(dataset_name)\n",
                "# Load train dataset\n",
                "train_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'train_filtered.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        train_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 100000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading train dataset, totally {} lines.'.format(len(train_review)))\n",
                "# Load test dataset\n",
                "test_review = []\n",
                "cnt = 0\n",
                "file_path = os.path.join(dir_path, 'test_filtered.json')\n",
                "with open(file_path) as f:\n",
                "    print(\"Load file: {}\".format(file_path))\n",
                "    for line in f:\n",
                "        line_data = json.loads(line)\n",
                "        user_id = line_data['user']\n",
                "        item_id = line_data['item']\n",
                "        rating = line_data['rating']\n",
                "        review = line_data['review']\n",
                "        test_review.append([item_id, user_id, rating, review])\n",
                "        cnt += 1\n",
                "        if cnt % 10000 == 0:\n",
                "            print('{} lines loaded.'.format(cnt))\n",
                "print('Finish loading test dataset, totally {} lines.'.format(len(test_review)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/wine/train_filtered.json\n",
                        "100000 lines loaded.\n",
                        "200000 lines loaded.\n",
                        "Finish loading train dataset, totally 248452 lines.\n",
                        "Load file: ../Dataset/wine/test_filtered.json\n",
                        "10000 lines loaded.\n",
                        "20000 lines loaded.\n",
                        "30000 lines loaded.\n",
                        "40000 lines loaded.\n",
                        "50000 lines loaded.\n",
                        "Finish loading test dataset, totally 59294 lines.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "df_train_data = pd.DataFrame(train_review, columns=['item', 'user', 'rating', 'review'])\n",
                "df_test_data = pd.DataFrame(test_review, columns=['item', 'user', 'rating', 'review'])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "df_train_data"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "           item    user  rating  \\\n",
                            "0       1015705  131074      93   \n",
                            "1        661436  131074      83   \n",
                            "2        458829  131074      92   \n",
                            "3        887649  131074      88   \n",
                            "4        744973  131074      90   \n",
                            "...         ...     ...     ...   \n",
                            "248447    70969  152917      93   \n",
                            "248448   470778  152917      88   \n",
                            "248449     1785  152917      90   \n",
                            "248450   481908  152917      95   \n",
                            "248451     2976  152917      88   \n",
                            "\n",
                            "                                                   review  \n",
                            "0       this wine is simply outstanding . the nose has...  \n",
                            "1       ripe but diluted bing cherry , a hint of spice...  \n",
                            "2       blackberry fruit and smoke . remarkable depth ...  \n",
                            "3       clear and crisp , tangy lemon and fresh vegeta...  \n",
                            "4       juicy young fruit . darker . currant . some pl...  \n",
                            "...                                                   ...  \n",
                            "248447  very structured , tannins still firm , a tad b...  \n",
                            "248448  me thinks this wine is passing it 's prime as ...  \n",
                            "248449  wonderfully aged bordeaux . it took about 5 to...  \n",
                            "248450  outstanding effort from kosta browne . i had t...  \n",
                            "248451  interesting wine ... i 'm about to go out on a...  \n",
                            "\n",
                            "[248452 rows x 4 columns]"
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1015705</td>\n",
                            "      <td>131074</td>\n",
                            "      <td>93</td>\n",
                            "      <td>this wine is simply outstanding . the nose has...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>661436</td>\n",
                            "      <td>131074</td>\n",
                            "      <td>83</td>\n",
                            "      <td>ripe but diluted bing cherry , a hint of spice...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>458829</td>\n",
                            "      <td>131074</td>\n",
                            "      <td>92</td>\n",
                            "      <td>blackberry fruit and smoke . remarkable depth ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>887649</td>\n",
                            "      <td>131074</td>\n",
                            "      <td>88</td>\n",
                            "      <td>clear and crisp , tangy lemon and fresh vegeta...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>744973</td>\n",
                            "      <td>131074</td>\n",
                            "      <td>90</td>\n",
                            "      <td>juicy young fruit . darker . currant . some pl...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>248447</th>\n",
                            "      <td>70969</td>\n",
                            "      <td>152917</td>\n",
                            "      <td>93</td>\n",
                            "      <td>very structured , tannins still firm , a tad b...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>248448</th>\n",
                            "      <td>470778</td>\n",
                            "      <td>152917</td>\n",
                            "      <td>88</td>\n",
                            "      <td>me thinks this wine is passing it 's prime as ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>248449</th>\n",
                            "      <td>1785</td>\n",
                            "      <td>152917</td>\n",
                            "      <td>90</td>\n",
                            "      <td>wonderfully aged bordeaux . it took about 5 to...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>248450</th>\n",
                            "      <td>481908</td>\n",
                            "      <td>152917</td>\n",
                            "      <td>95</td>\n",
                            "      <td>outstanding effort from kosta browne . i had t...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>248451</th>\n",
                            "      <td>2976</td>\n",
                            "      <td>152917</td>\n",
                            "      <td>88</td>\n",
                            "      <td>interesting wine ... i 'm about to go out on a...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>248452 rows × 4 columns</p>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 6
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# groupby multiple columns\n",
                "groupby_user_item = df_train_data.groupby(['user', 'item'])\n",
                "cnt = 0\n",
                "for key, item in groupby_user_item:\n",
                "    cur_df_user_item = groupby_user_item.get_group(key)\n",
                "    if len(cur_df_user_item) > 1:\n",
                "        if cnt <= 10:\n",
                "            print(cur_df_user_item)\n",
                "        cnt += 1\n",
                "print(\"{} data instance are the same\".format(cnt))\n",
                "# make sure that there are no duplicated reviews"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 data instance are the same\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Sentence2ID and ID2Sentence Mapping"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "sentence2id_filepath = '../Dataset/{}/train/sentence/sentence2id.json'.format(dataset_name)\n",
                "with open(sentence2id_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(sentence2id_filepath))\n",
                "    sent_to_id = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/wine/train/sentence/sentence2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "type(sent_to_id['very nice wine .'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "str"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "id2sentence_filepath = '../Dataset/{}/train/sentence/id2sentence.json'.format(dataset_name)\n",
                "with open(id2sentence_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(id2sentence_filepath))\n",
                "    id_to_sent = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/wine/train/sentence/id2sentence.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "id_to_sent['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'very nice wine .'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 12
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "assert len(sent_to_id) == len(id_to_sent)\n",
                "print(\"Number of sentence (with feature) on train set: {}\".format(len(sent_to_id)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Number of sentence (with feature) on train set: 554564\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Feature Words"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "feature2id_filepath = '../Dataset/{}/train/feature/feature2id.json'.format(dataset_name)\n",
                "with open(feature2id_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(feature2id_filepath))\n",
                "    feature_vocab = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/wine/train/feature/feature2id.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "len(feature_vocab)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "215"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 15
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "feature_vocab['aroma']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "'28'"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 16
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Load Sentence2Feature"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "sentence2feature_filepath = '../Dataset/{}/train/sentence/sentence2feature.json'.format(dataset_name)\n",
                "with open(sentence2feature_filepath, 'r') as f:\n",
                "    print(\"Load file: {}\".format(sentence2feature_filepath))\n",
                "    sentence_to_feature = json.load(f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Load file: ../Dataset/wine/train/sentence/sentence2feature.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "source": [
                "sentence_to_feature['0']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "{'0': 1.0}"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 19
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "assert len(sentence_to_feature) == len(sent_to_id)\n",
                "len(sentence_to_feature)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "554564"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 18
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Construct User-Item Pair\n",
                "## GroupBy User"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "group_by_user = df_train_data.groupby('user')\n",
                "group_by_user_dict = dict(tuple(group_by_user))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "group_by_user_dict['3']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "      item user  rating                                             review\n",
                            "70   77773    3      90  served with fresh black italian truffles over ...\n",
                            "71  788700    3      91  beautiful wine - yeast , nutty bread , dry & c...\n",
                            "72  178465    3      90  delicious bottle , none of us familiar with it...\n",
                            "73     246    3      90  a delightful surprise ... wonderful floral ( v...\n",
                            "74    7570    3      89  a v ery concentrated and big wine ... spciy , ...\n",
                            "75     251    3      90  a very pleasant surprise ! drank w/markj over ...\n",
                            "76    4260    3      91  outstanding ! fresh back from spain , and havi...\n",
                            "77  288673    3      89  dark , concentrated , very young , but delightful\n",
                            "78    7103    3      85  initial nose had touch of ammonia , which diss...\n",
                            "79    4350    3      90  fantastic ! dominant notes of vibrant fruit an...\n",
                            "80  219158    3      90  tight bubbles , beautiful pale golden color , ...\n",
                            "81  393502    3      91  over the top bruiser at this stage ... huge wi...\n",
                            "82  131964    3      91              fabulous wine - powerful & brooding .\n",
                            "83  205367    3      90  perfect example of sparkling chenin ... and an...\n",
                            "84    8006    3      90  beautiful pink color , aroma and mouth redolen...\n",
                            "85    6020    3      92  wow ! luscious bottle of wine - nose & palate ..."
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>70</th>\n",
                            "      <td>77773</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>served with fresh black italian truffles over ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>71</th>\n",
                            "      <td>788700</td>\n",
                            "      <td>3</td>\n",
                            "      <td>91</td>\n",
                            "      <td>beautiful wine - yeast , nutty bread , dry &amp; c...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>72</th>\n",
                            "      <td>178465</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>delicious bottle , none of us familiar with it...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>73</th>\n",
                            "      <td>246</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>a delightful surprise ... wonderful floral ( v...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>74</th>\n",
                            "      <td>7570</td>\n",
                            "      <td>3</td>\n",
                            "      <td>89</td>\n",
                            "      <td>a v ery concentrated and big wine ... spciy , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>75</th>\n",
                            "      <td>251</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>a very pleasant surprise ! drank w/markj over ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>76</th>\n",
                            "      <td>4260</td>\n",
                            "      <td>3</td>\n",
                            "      <td>91</td>\n",
                            "      <td>outstanding ! fresh back from spain , and havi...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>77</th>\n",
                            "      <td>288673</td>\n",
                            "      <td>3</td>\n",
                            "      <td>89</td>\n",
                            "      <td>dark , concentrated , very young , but delightful</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>78</th>\n",
                            "      <td>7103</td>\n",
                            "      <td>3</td>\n",
                            "      <td>85</td>\n",
                            "      <td>initial nose had touch of ammonia , which diss...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>79</th>\n",
                            "      <td>4350</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>fantastic ! dominant notes of vibrant fruit an...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>80</th>\n",
                            "      <td>219158</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>tight bubbles , beautiful pale golden color , ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>81</th>\n",
                            "      <td>393502</td>\n",
                            "      <td>3</td>\n",
                            "      <td>91</td>\n",
                            "      <td>over the top bruiser at this stage ... huge wi...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>82</th>\n",
                            "      <td>131964</td>\n",
                            "      <td>3</td>\n",
                            "      <td>91</td>\n",
                            "      <td>fabulous wine - powerful &amp; brooding .</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>83</th>\n",
                            "      <td>205367</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>perfect example of sparkling chenin ... and an...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>84</th>\n",
                            "      <td>8006</td>\n",
                            "      <td>3</td>\n",
                            "      <td>90</td>\n",
                            "      <td>beautiful pink color , aroma and mouth redolen...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>85</th>\n",
                            "      <td>6020</td>\n",
                            "      <td>3</td>\n",
                            "      <td>92</td>\n",
                            "      <td>wow ! luscious bottle of wine - nose &amp; palate ...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 21
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "len(group_by_user_dict)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "6080"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "user_id_list = list(df_train_data['user'].unique())"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "source": [
                "print(len(user_id_list))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "6080\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "source": [
                "user_to_sent = dict()\n",
                "cnt_sentence_with_no_feature = 0\n",
                "\n",
                "for user_id in user_id_list:\n",
                "    # note this user_id is a str\n",
                "    # get the dataframe for this user\n",
                "    user_df = group_by_user_dict[user_id]\n",
                "    user_reviews = list(user_df['review'])\n",
                "    user_sent_ids = set()\n",
                "    for review in user_reviews:\n",
                "        # tokenize this review (i.e. split into sentences)\n",
                "        review_sents = sent_tokenize(review)\n",
                "        # check whether the sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                # assert cur_sent_id in sentence_to_feature\n",
                "                # user_sent_ids.add(cur_sent_id)\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of this user\n",
                "                    user_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    cnt_sentence_with_no_feature += 1\n",
                "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
                "    if len(user_sent_ids) == 0:\n",
                "        print(\"User: {} has no effective sentences, skip it.\".format(user_id))\n",
                "    else:\n",
                "        user_to_sent[user_id] = user_sent_ids\n",
                "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 sentence with no feature\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "source": [
                "len(user_to_sent)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "6080"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 26
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "source": [
                "user_to_sentids = dict()\n",
                "for user_id, user_sents in user_to_sent.items():\n",
                "    assert len(user_sents) > 0\n",
                "    assert isinstance(user_id, str)\n",
                "    assert isinstance(list(user_sents)[0], str)\n",
                "    user_to_sentids[user_id] = list(user_sents)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "source": [
                "len(user_to_sentids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "6080"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 28
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "source": [
                "user2sentids_filepath = '../Dataset//{}/train/user/user2sentids.json'.format(dataset_name)\n",
                "with open(user2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(user2sentids_filepath))\n",
                "    json.dump(user_to_sentids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset//wine/train/user/user2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "source": [
                "user_side_cdd_sents_num = list()\n",
                "for key, value in user_to_sentids.items():\n",
                "    user_side_cdd_sents_num.append(len(value))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "source": [
                "print(\"Mean number of sentence per user: {}\".format(\n",
                "    np.mean(user_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Min number of sentence per user: {}\".format(\n",
                "    np.min(user_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Max number of sentence per user: {}\".format(\n",
                "    np.max(user_side_cdd_sents_num)\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of sentence per user: 93.92467105263158\n",
                        "Min number of sentence per user: 1\n",
                        "Max number of sentence per user: 1529\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "source": [
                "print(\"Top-10 least numbber of sentences per user: {}\".format(\n",
                "    sorted(user_side_cdd_sents_num)[:10]\n",
                "))\n",
                "print(\"Top-10 most numbber of sentences per user: {}\".format(\n",
                "    sorted(user_side_cdd_sents_num)[-10:]\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Top-10 least numbber of sentences per user: [1, 2, 3, 4, 5, 5, 6, 6, 7, 7]\n",
                        "Top-10 most numbber of sentences per user: [1032, 1033, 1034, 1077, 1148, 1183, 1197, 1237, 1473, 1529]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## GrounBy Item"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "source": [
                "group_by_item = df_train_data.groupby('item')\n",
                "group_by_item_dict = dict(tuple(group_by_item))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "source": [
                "group_by_item_dict['14785']"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "         item   user  rating  \\\n",
                            "5412    14785    193      90   \n",
                            "13300   14785    809      89   \n",
                            "18527   14785   1417      93   \n",
                            "45913   14785   7887      91   \n",
                            "76826   14785  14747      90   \n",
                            "101169  14785  23509      91   \n",
                            "151235  14785  41815      92   \n",
                            "175729  14785  53459      88   \n",
                            "\n",
                            "                                                   review  \n",
                            "5412    this winery continues to be a great qpr and th...  \n",
                            "13300   dinner at plateau club - a very nice cab , cle...  \n",
                            "18527                                    beautiful wine .  \n",
                            "45913   this is really drinking well right now . plent...  \n",
                            "76826   really good now , berry cassis and hint of oak...  \n",
                            "101169  dark red with slight fade at rim . wonderfully...  \n",
                            "151235  that is some kind of cabernet sauvignon i tell...  \n",
                            "175729  strawberries and blueberries , pops out at you...  "
                        ],
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>item</th>\n",
                            "      <th>user</th>\n",
                            "      <th>rating</th>\n",
                            "      <th>review</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>5412</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>193</td>\n",
                            "      <td>90</td>\n",
                            "      <td>this winery continues to be a great qpr and th...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>13300</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>809</td>\n",
                            "      <td>89</td>\n",
                            "      <td>dinner at plateau club - a very nice cab , cle...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>18527</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>1417</td>\n",
                            "      <td>93</td>\n",
                            "      <td>beautiful wine .</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>45913</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>7887</td>\n",
                            "      <td>91</td>\n",
                            "      <td>this is really drinking well right now . plent...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>76826</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>14747</td>\n",
                            "      <td>90</td>\n",
                            "      <td>really good now , berry cassis and hint of oak...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>101169</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>23509</td>\n",
                            "      <td>91</td>\n",
                            "      <td>dark red with slight fade at rim . wonderfully...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>151235</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>41815</td>\n",
                            "      <td>92</td>\n",
                            "      <td>that is some kind of cabernet sauvignon i tell...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>175729</th>\n",
                            "      <td>14785</td>\n",
                            "      <td>53459</td>\n",
                            "      <td>88</td>\n",
                            "      <td>strawberries and blueberries , pops out at you...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 31
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "len(group_by_item_dict)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "15253"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 32
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "source": [
                "item_id_list = list(df_train_data['item'].unique())\n",
                "item_to_sent = dict()\n",
                "cnt_sentence_with_no_feature = 0\n",
                "for item_id in item_id_list:\n",
                "    # note this item_id is a str\n",
                "    # get the dataframe for this item\n",
                "    assert isinstance(item_id, str)\n",
                "    item_df = group_by_item_dict[item_id]\n",
                "    item_reviews = list(item_df['review'])\n",
                "    item_sent_ids = set()\n",
                "    for review in item_reviews:\n",
                "        # tokenize this review (i.e. split into sentences)\n",
                "        review_sents = sent_tokenize(review)\n",
                "        # check whether the sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of this user\n",
                "                    item_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    cnt_sentence_with_no_feature += 1\n",
                "        # TODO: what should we do if there are sentence that appears in multiple reivews?\n",
                "    if len(item_sent_ids) == 0:\n",
                "        print(\"Item {} has no effective sentence, skip it.\".format(item_id))\n",
                "    else:\n",
                "        item_to_sent[item_id] = item_sent_ids\n",
                "\n",
                "print('{} sentence with no feature'.format(cnt_sentence_with_no_feature))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 sentence with no feature\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "source": [
                "len(item_to_sent)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "15253"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 34
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "source": [
                "item_to_sentids = dict()\n",
                "for item_id, item_sents in item_to_sent.items():\n",
                "    assert len(item_sents) > 0\n",
                "    assert isinstance(list(item_sents)[0], str)\n",
                "    item_to_sentids[item_id] = list(item_sents)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "source": [
                "len(item_to_sentids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "15253"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 36
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "source": [
                "item2sentids_filepath = '../Dataset/{}/train/item/item2sentids.json'.format(dataset_name)\n",
                "with open(item2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(item2sentids_filepath))\n",
                "    json.dump(item_to_sentids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/wine/train/item/item2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "source": [
                "item_side_cdd_sents_num = list()\n",
                "for key, value in item_to_sentids.items():\n",
                "    item_side_cdd_sents_num.append(len(value))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "source": [
                "print(\"Mean number of sentence per item: {}\".format(\n",
                "    np.mean(item_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Min number of sentence per item: {}\".format(\n",
                "    np.min(item_side_cdd_sents_num)\n",
                "))\n",
                "print(\"Max number of sentence per item: {}\".format(\n",
                "    np.max(item_side_cdd_sents_num)\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Mean number of sentence per item: 37.76299744312594\n",
                        "Min number of sentence per item: 5\n",
                        "Max number of sentence per item: 452\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "source": [
                "print(\"Top-10 least numbber of sentence per item: {}\".format(\n",
                "    sorted(item_side_cdd_sents_num)[:10]\n",
                "))\n",
                "print(\"Top-10 most numbber of sentence per item: {}\".format(\n",
                "    sorted(item_side_cdd_sents_num)[-10:]\n",
                "))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Top-10 least numbber of sentence per item: [5, 5, 5, 5, 6, 6, 6, 6, 6, 6]\n",
                        "Top-10 most numbber of sentence per item: [300, 302, 304, 315, 318, 320, 358, 365, 426, 452]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# For Each Data Instance in TrainSet"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "source": [
                "import random\n",
                "sample_sent_num = 500\n",
                "user_item_candidate_sent_ids = dict()\n",
                "# Loop over all User\n",
                "user_cnt = 0\n",
                "review_cnt = 0\n",
                "review_with_no_selectd_label_sentence = 0\n",
                "useable_review_cnt = 0\n",
                "sentence_with_no_feature_cnt = 0\n",
                "sentence_not_tracked = set()\n",
                "for user_df_chunk in list(group_by_user):\n",
                "    user_id = int(user_df_chunk[0])\n",
                "    user_id_str = str(user_df_chunk[0])\n",
                "    user_df = user_df_chunk[1]\n",
                "    # get user sents\n",
                "    cur_user_sent_ids = user_to_sent[user_id_str]\n",
                "    # item-level dict\n",
                "    item_candidate_sent_ids = dict()\n",
                "    for idx, row in user_df.iterrows():\n",
                "        item_id = int(row['item'])\n",
                "        item_id_str = str(row['item'])\n",
                "        review_text = row['review']\n",
                "        review_cnt += 1\n",
                "        # get item sents\n",
                "        cur_item_sent_ids = item_to_sent[item_id_str]\n",
                "        # get review_text's sent ids\n",
                "        cur_review_sent_ids = set()\n",
                "        ## tokenize this review\n",
                "        review_sents = sent_tokenize(review_text)\n",
                "        ## check whether this sentence is in the sentence2id dictionary\n",
                "        for sent in review_sents:\n",
                "            if sent in sent_to_id:\n",
                "                cur_sent_id = sent_to_id[sent]\n",
                "                assert isinstance(cur_sent_id, str)\n",
                "                # make sure that this sentence has feature\n",
                "                if cur_sent_id in sentence_to_feature:\n",
                "                    # add this sentence into the set of current review\n",
                "                    cur_review_sent_ids.add(cur_sent_id)\n",
                "                else:\n",
                "                    sentence_with_no_feature_cnt += 1\n",
                "            else:\n",
                "                # if this sentence is not being tracked by the sentence-id mapping\n",
                "                # we add it into this set to see how many sentences are being ignored\n",
                "                sentence_not_tracked.add(sent)\n",
                "        ## check whether the true label of the sentence is an empty list of sent_ids\n",
                "        if len(cur_review_sent_ids) == 0:\n",
                "            review_with_no_selectd_label_sentence += 1\n",
                "        else:\n",
                "            # construct the candidate set which is an union of user sentences and item sentences\n",
                "            cur_useritem_sent_ids = cur_user_sent_ids | cur_item_sent_ids\n",
                "            # sample some sentences\n",
                "            if len(cur_useritem_sent_ids) > sample_sent_num:\n",
                "                sample_useritem_sent_ids = set(random.sample(cur_useritem_sent_ids, sample_sent_num))\n",
                "            else:\n",
                "                sample_useritem_sent_ids = cur_useritem_sent_ids\n",
                "            # union sampled sentences with true labeled sentences\n",
                "            final_useritem_sent_ids = sample_useritem_sent_ids | cur_review_sent_ids\n",
                "            # add this into the dict\n",
                "            item_candidate_sent_ids[item_id_str] = [list(final_useritem_sent_ids), list(cur_review_sent_ids)]\n",
                "            # add useable review cnt\n",
                "            useable_review_cnt += 1\n",
                "    if len(item_candidate_sent_ids) == 0:\n",
                "        print(\"User: {} has no useful item, skip this user ...\".format(user_id_str))\n",
                "    else:\n",
                "        # add the item_candidate_sent_ids dict into the user-level dict\n",
                "        user_item_candidate_sent_ids[user_id_str] = item_candidate_sent_ids\n",
                "    user_cnt += 1\n",
                "    if user_cnt % 200 == 0:\n",
                "        print(\"{} user processed\".format(user_cnt))\n",
                "\n",
                "print('Finish.')\n",
                "print('Totally {} users'.format(user_cnt))\n",
                "print('Totally {0} reviews. Among them {1} reviews has empty true label sentence'.format(\n",
                "    review_cnt, review_with_no_selectd_label_sentence))\n",
                "print(\"{} sentences has 0 feature\".format(sentence_with_no_feature_cnt))\n",
                "print(\"{} sentences are not being tracked in the sent2id mapping\".format(len(sentence_not_tracked)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "200 user processed\n",
                        "400 user processed\n",
                        "600 user processed\n",
                        "800 user processed\n",
                        "1000 user processed\n",
                        "1200 user processed\n",
                        "1400 user processed\n",
                        "1600 user processed\n",
                        "1800 user processed\n",
                        "2000 user processed\n",
                        "2200 user processed\n",
                        "2400 user processed\n",
                        "2600 user processed\n",
                        "2800 user processed\n",
                        "3000 user processed\n",
                        "3200 user processed\n",
                        "3400 user processed\n",
                        "3600 user processed\n",
                        "3800 user processed\n",
                        "4000 user processed\n",
                        "4200 user processed\n",
                        "4400 user processed\n",
                        "4600 user processed\n",
                        "4800 user processed\n",
                        "5000 user processed\n",
                        "5200 user processed\n",
                        "5400 user processed\n",
                        "5600 user processed\n",
                        "5800 user processed\n",
                        "6000 user processed\n",
                        "Finish.\n",
                        "Totally 6080 users\n",
                        "Totally 248452 reviews. Among them 2651 reviews has empty true label sentence\n",
                        "0 sentences has 0 feature\n",
                        "386202 sentences are not being tracked in the sent2id mapping\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "len(user_item_candidate_sent_ids)"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "6080"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 48
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "# let's check how many unique reviews are there\n",
                "\n",
                "cnt_unique_reviews = 0\n",
                "cnt_empty_true_sent = 0\n",
                "sentence_per_review = []\n",
                "candidate_sentence_num_cnt_per_review = []\n",
                "# [user-level] Loop for each user\n",
                "for user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "    user_id_str = str(user_chunk[0])\n",
                "    # assert isinstance(user_chunk[0], str)\n",
                "    # [item-level] Loop for each user-item pair\n",
                "    user_item_chunks = list(user_chunk[1].items())\n",
                "    for item_chunk in user_item_chunks:\n",
                "        item_id_str = str(item_chunk[0])\n",
                "        # assert isinstance(item_chunk[0], str)\n",
                "        candidate_sent_ids = item_chunk[1][0]\n",
                "        true_sent_ids = item_chunk[1][1]\n",
                "        if len(true_sent_ids) == 0:\n",
                "            cnt_empty_true_sent += 1\n",
                "        else:\n",
                "            assert isinstance(candidate_sent_ids[0], str)\n",
                "            assert isinstance(true_sent_ids[0], str)\n",
                "            # make sure that all true label sent_ids appears in the corresponding candidate set\n",
                "            for true_sent_id in true_sent_ids:\n",
                "                assert true_sent_id in candidate_sent_ids\n",
                "            sentence_per_review.append(len(true_sent_ids))\n",
                "            candidate_sentence_num_cnt_per_review.append(len(candidate_sent_ids))\n",
                "        cnt_unique_reviews += 1\n",
                "\n",
                "print(\"Total number of unique selected reviews: {}\".format(cnt_unique_reviews))\n",
                "print(\"Total number of review with empty true sentences: {}\".format(cnt_empty_true_sent))\n",
                "print(\"Total number of unique review with non-empty true sentences: {}\".format(\n",
                "    cnt_unique_reviews - cnt_empty_true_sent))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Total number of unique selected reviews: 245801\n",
                        "Total number of review with empty true sentences: 0\n",
                        "Total number of unique review with non-empty true sentences: 245801\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "source": [
                "print(\"Totally {} user-item pairs in the trainset\".format(len(sentence_per_review)))\n",
                "print(\"max number of true sentence per review: {}\".format(np.max(sentence_per_review)))\n",
                "print(\"min number of true sentence per review: {}\".format(np.min(sentence_per_review)))\n",
                "print(\"mean number of true sentence per review: {}\".format(np.mean(sentence_per_review)))\n",
                "print(\"max number of candidate sentence per review: {}\".format(np.max(candidate_sentence_num_cnt_per_review)))\n",
                "print(\"min number of candidate sentence per review: {}\".format(np.min(candidate_sentence_num_cnt_per_review)))\n",
                "print(\"mean number of candidate sentence per review: {}\".format(np.mean(candidate_sentence_num_cnt_per_review)))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Totally 245801 user-item pairs in the trainset\n",
                        "max number of true sentence per review: 30\n",
                        "min number of true sentence per review: 1\n",
                        "mean number of true sentence per review: 2.3441076317834346\n",
                        "max number of candidate sentence per review: 514\n",
                        "min number of candidate sentence per review: 10\n",
                        "mean number of candidate sentence per review: 254.12354709704192\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "source": [
                "useritem2sentids_filepath = '../Dataset/{}/train/useritem2sentids.json'.format(dataset_name)\n",
                "with open(useritem2sentids_filepath, 'w') as f:\n",
                "    print(\"Write file: {}\".format(useritem2sentids_filepath))\n",
                "    json.dump(user_item_candidate_sent_ids, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/wine/train/useritem2sentids.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "len(user_item_candidate_sent_ids['3']['246'][0])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "51"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 52
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "source": [
                "len(user_to_sent['3'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "26"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 53
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "source": [
                "len(item_to_sent['246'])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "27"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 55
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "source": [
                "len(user_item_candidate_sent_ids['3']['246'][1])"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "2"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 56
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "source": [
                "for sent_id in user_item_candidate_sent_ids['3']['246'][1]:\n",
                "    assert sent_id in user_item_candidate_sent_ids['3']['246'][0]"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Write train useritem_cdd in a line-by-line format"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "source": [
                "# Write useritem2sentids into a line-by-line format\n",
                "train_useritem2sentid_multiline_file = '../Dataset/{}/train/useritem2sentids_multilines.json'.format(dataset_name)\n",
                "if os.path.exists(train_useritem2sentid_multiline_file):\n",
                "    print(\"File: {} exists, remove it.\".format(train_useritem2sentid_multiline_file))\n",
                "    os.remove(train_useritem2sentid_multiline_file)\n",
                "else:\n",
                "    print(\"File: {} doesn't exist, creat it.\".format(train_useritem2sentid_multiline_file))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "File: ../Dataset/wine/train/useritem2sentids_multilines.json doesn't exist, creat it.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "source": [
                "with open(train_useritem2sentid_multiline_file, 'a') as f1:\n",
                "    print(\"Write file: {}\".format(train_useritem2sentid_multiline_file))\n",
                "    cnt_user = 0\n",
                "    cnt_review = 0\n",
                "    user_set = set()\n",
                "    item_set = set()\n",
                "    useritem_set = set()\n",
                "    for trainset_user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "        assert isinstance(trainset_user_chunk[0], str)\n",
                "        user_id_str = trainset_user_chunk[0]\n",
                "        user_id = int(trainset_user_chunk[0])\n",
                "        user_item_chunks = list(trainset_user_chunk[1].items())\n",
                "        for item_chunk in user_item_chunks:\n",
                "            assert isinstance(item_chunk[0], str)\n",
                "            item_id_str = item_chunk[0]\n",
                "            item_id = int(item_chunk[0])\n",
                "            candidate_sent_ids = item_chunk[1][0]\n",
                "            gold_revw_sent_ids = item_chunk[1][1]\n",
                "            assert isinstance(candidate_sent_ids, list)\n",
                "            assert isinstance(gold_revw_sent_ids, list)\n",
                "            assert isinstance(candidate_sent_ids[0], str)\n",
                "            assert isinstance(gold_revw_sent_ids[0], str)\n",
                "            for cur_id in gold_revw_sent_ids:\n",
                "                assert cur_id in candidate_sent_ids\n",
                "            cur_data_dict = {'user_id': user_id_str, 'item_id': item_id_str, 'candidate': candidate_sent_ids, \"review\": gold_revw_sent_ids}\n",
                "            # write this into the json file\n",
                "            json.dump(cur_data_dict, f1)\n",
                "            f1.write(\"\\n\")\n",
                "            cnt_review += 1\n",
                "            useritem_set.add((user_id_str, item_id_str))\n",
                "            item_set.add(item_id_str)\n",
                "            if cnt_review % 50000 == 0:\n",
                "                print(\"{} lines of train data written.\".format(cnt_review))\n",
                "        cnt_user += 1\n",
                "        user_set.add(user_id_str)\n",
                "\n",
                "assert cnt_user == len(user_set)\n",
                "assert cnt_review == len(useritem_set)\n",
                "print(\"Totally {} users\".format(cnt_user))\n",
                "print(\"Totally {} items\".format(len(item_set)))\n",
                "print(\"Totally {} reviews\".format(cnt_review))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Write file: ../Dataset/wine/train/useritem2sentids_multilines.json\n",
                        "50000 lines of train data written.\n",
                        "100000 lines of train data written.\n",
                        "150000 lines of train data written.\n",
                        "200000 lines of train data written.\n",
                        "Totally 6080 users\n",
                        "Totally 15253 items\n",
                        "Totally 245801 reviews\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "source": [
                "!head -n 1 '../Dataset/wine/train/useritem2sentids_multilines.json'"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{\"user_id\": \"100\", \"item_id\": \"1113634\", \"candidate\": [\"14360\", \"14601\", \"14462\", \"14477\", \"334751\", \"14412\", \"14426\", \"401123\", \"14509\", \"14676\", \"64804\", \"352507\", \"2822\", \"14507\", \"14608\", \"14504\", \"14585\", \"14387\", \"14599\", \"327393\", \"14680\", \"386215\", \"401122\", \"346833\", \"437184\", \"501682\", \"14396\", \"14366\", \"14416\", \"329746\", \"14674\", \"14634\", \"14513\", \"14522\", \"14700\", \"320831\", \"14618\", \"325917\", \"14590\", \"516924\", \"14503\", \"14451\", \"14673\", \"219511\", \"875\", \"14380\", \"14400\", \"327390\", \"14485\", \"447671\", \"14393\", \"516925\", \"14395\", \"14576\", \"14571\", \"14392\", \"14381\", \"14709\", \"14528\", \"14406\", \"14583\", \"14466\", \"64803\", \"14559\", \"14667\", \"14478\", \"14549\", \"14373\", \"14708\", \"14610\", \"14461\", \"14473\", \"14616\", \"14597\", \"14611\", \"14703\", \"14565\", \"14632\", \"14697\", \"394227\", \"539457\", \"14383\", \"14414\", \"14415\", \"437186\", \"14482\", \"501683\", \"14658\", \"14615\", \"14584\", \"14551\", \"166\", \"14463\", \"14517\", \"386217\", \"14612\", \"14564\", \"14410\", \"386218\", \"14550\", \"293290\", \"320830\", \"14644\", \"486660\", \"14388\", \"14707\", \"320829\", \"14566\", \"401121\", \"14476\", \"14529\", \"14367\", \"14678\", \"394228\", \"14390\", \"14494\", \"14672\", \"14664\", \"14646\", \"14532\", \"14662\", \"14465\", \"14496\", \"14687\", \"14434\", \"14493\", \"14661\", \"293293\", \"74\", \"14425\", \"14428\", \"352508\", \"14527\", \"320832\", \"0\", \"14371\", \"14628\", \"14516\", \"14438\", \"14684\", \"14486\", \"14435\", \"14499\", \"14437\", \"486657\", \"14459\", \"14648\", \"14441\", \"14515\", \"14427\", \"14454\", \"14629\", \"14447\", \"394229\", \"14582\", \"14446\", \"14411\", \"14484\", \"128299\", \"14540\", \"14625\", \"364280\", \"14429\", \"14621\", \"14409\", \"14449\", \"14512\", \"14556\", \"14452\", \"14362\", \"545040\", \"14572\", \"14653\", \"14557\", \"14696\", \"505430\", \"14506\", \"14694\", \"14657\", \"14574\", \"14376\", \"14445\", \"14705\", \"14467\", \"14569\", \"1720\", \"14531\", \"14637\", \"516926\", \"14647\", \"14524\", \"14511\", \"14568\", \"14627\", \"14430\", \"14614\", \"14401\", \"293291\", \"14633\", \"325918\", \"340\", \"14413\", \"14640\", \"14555\", \"505431\", \"14405\", \"14518\", \"14613\", \"14495\", \"513671\", \"14489\", \"14592\", \"14448\", \"340071\", \"14475\", \"14364\", \"14490\", \"14671\", \"14623\", \"14605\", \"1186\", \"14458\", \"14561\", \"219512\", \"14421\", \"14600\", \"14643\", \"14368\", \"14502\", \"386216\", \"14635\", \"14525\", \"14530\", \"14359\", \"14510\", \"14677\", \"14636\", \"14679\", \"14442\", \"14379\", \"14650\", \"362175\", \"14479\", \"325915\", \"14538\", \"14588\", \"14666\", \"14385\", \"14609\", \"14626\", \"345481\", \"14399\", \"14384\", \"14491\", \"14665\", \"14468\", \"14704\", \"14607\", \"505428\", \"14639\", \"14487\", \"14357\", \"14375\", \"505429\", \"14363\", \"14370\", \"14472\", \"14505\", \"14686\", \"14474\", \"14589\", \"14372\", \"14552\", \"334752\", \"14382\", \"14695\", \"14402\", \"14436\", \"14630\", \"14595\", \"346835\", \"14654\", \"2824\", \"14389\", \"14361\", \"14604\", \"14536\", \"14649\", \"14619\", \"14660\", \"14365\", \"14483\", \"14685\", \"14450\", \"14492\", \"14579\", \"501681\", \"64805\", \"14488\", \"14580\", \"14444\", \"14369\", \"14356\", \"14563\", \"14691\", \"14391\", \"14537\", \"14688\", \"14431\", \"14420\", \"14693\", \"128298\", \"256344\", \"14682\", \"2825\", \"14424\", \"437183\", \"14577\", \"14419\", \"14598\", \"352509\", \"327392\", \"14651\", \"14698\", \"14554\", \"14617\", \"14377\", \"14641\", \"14543\", \"14464\", \"14586\", \"401120\", \"329747\", \"14501\", \"14508\", \"14470\", \"14432\", \"14594\", \"14656\", \"14681\", \"325914\", \"486659\", \"14683\", \"14460\", \"14624\", \"14497\", \"401119\", \"14523\", \"14407\", \"14397\", \"14500\", \"14455\", \"256345\", \"2823\", \"14575\", \"14591\", \"513672\", \"14520\", \"14433\", \"14544\", \"14443\", \"14645\", \"64806\", \"14526\", \"447669\", \"14519\", \"14471\", \"14546\", \"14521\", \"14702\", \"434137\", \"394230\", \"14498\", \"14386\", \"293292\", \"14545\", \"14659\", \"14593\", \"14457\", \"876\", \"14456\", \"14440\", \"346834\", \"14422\", \"14534\", \"14663\", \"325913\", \"14403\", \"14423\", \"14453\", \"14622\", \"14374\", \"14655\", \"14670\", \"14706\", \"14418\", \"75\", \"14570\", \"128297\", \"14535\", \"14669\", \"1\", \"486658\", \"14642\", \"14480\", \"14573\", \"14620\", \"14548\", \"14417\", \"14533\", \"14547\", \"14710\", \"14408\", \"14558\", \"14394\", \"14562\", \"14587\", \"14692\", \"14699\", \"14439\", \"447670\", \"14567\", \"14638\", \"437185\", \"14541\", \"14668\", \"14542\", \"14606\", \"14481\", \"539458\", \"14398\", \"14631\", \"1676\", \"14701\", \"325916\", \"14581\", \"14603\", \"14578\", \"362176\", \"14675\", \"14514\", \"14404\", \"327391\", \"14690\", \"14596\", \"14358\", \"14378\", \"14553\", \"14652\", \"14560\", \"14602\", \"14539\", \"14469\", \"14689\"], \"review\": [\"14356\", \"14357\"]}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Save User-Item Pairs (Train Set)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "source": [
                "user_item_pairs = dict()\n",
                "cnt_user_item_pairs = 0\n",
                "for trainset_user_chunk in list(user_item_candidate_sent_ids.items()):\n",
                "    assert isinstance(trainset_user_chunk[0], str)\n",
                "    user_id_str = trainset_user_chunk[0]\n",
                "    user_item_chunks = list(trainset_user_chunk[1].items())\n",
                "    assert user_id_str not in user_item_pairs\n",
                "    user_item_pairs[user_id_str] = list()\n",
                "    for item_chunk in user_item_chunks:\n",
                "        assert isinstance(item_chunk[0], str)\n",
                "        item_id_str = item_chunk[0]\n",
                "        assert item_id_str not in user_item_pairs[user_id_str]\n",
                "        user_item_pairs[user_id_str].append(item_id_str)\n",
                "        cnt_user_item_pairs += 1\n",
                "print(\"Total number of user-item pair on trainset: {}\".format(cnt_user_item_pairs))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Total number of user-item pair on trainset: 245801\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "source": [
                "train_useritempairs_file = '../Dataset/{}/train/useritem_pairs.json'.format(dataset_name)\n",
                "with open(train_useritempairs_file, 'w') as f:\n",
                "    print(\"write file: {}\".format(train_useritempairs_file))\n",
                "    json.dump(user_item_pairs, f)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "write file: ../Dataset/wine/train/useritem_pairs.json\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.3",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.3 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "73d0647c863cb9ce92fb50b3911519dc6558e38bcfd5798aa86981c2dac43fdf"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}